{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p000001</td>\n",
       "      <td>Cap Barbell 300 Pound Olympic Set, Grey Cap Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p000002</td>\n",
       "      <td>10 Sony Headphones (BUY 9 GET 1 FREE) Belkin 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p000003</td>\n",
       "      <td>EE820X - Phonemic Awareness Instant Learning C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p000004</td>\n",
       "      <td>A Bad Case of the Giggles Poems That Will Make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p000005</td>\n",
       "      <td>Fitbit Zip Wireless Activity Tracker, Lime Fit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description\n",
       "0  p000001  Cap Barbell 300 Pound Olympic Set, Grey Cap Ba...\n",
       "1  p000002  10 Sony Headphones (BUY 9 GET 1 FREE) Belkin 6...\n",
       "2  p000003  EE820X - Phonemic Awareness Instant Learning C...\n",
       "3  p000004  A Bad Case of the Giggles Poems That Will Make...\n",
       "4  p000005  Fitbit Zip Wireless Activity Tracker, Lime Fit..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard import summary as summary_lib\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "dir='/Users/xinwang/ai/dataset/kaggle/DonorsChoose/'\n",
    "train_file=dir + 'train_1.csv'\n",
    "eval_file=dir + 'train_2.csv'\n",
    "resource_file = dir + 'resources.csv'\n",
    "model_dir = \"/Users/xinwang/Downloads/models_temp/\"\n",
    "label = LabelEncoder()\n",
    "\n",
    "CSV_COLUMNS = ['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
    "       'project_submitted_datetime', 'project_grade_category',\n",
    "       'project_subject_categories', 'project_subject_subcategories',\n",
    "       'project_title', 'project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
    "       'teacher_number_of_previously_posted_projects', 'project_is_approved']\n",
    "RESOURCE_COLUMNS = ['id', 'description', 'quantity', 'price']\n",
    "target = 'project_is_approved'\n",
    "\n",
    "summary_vocab_size=10000\n",
    "summary_sentence_size=50\n",
    "summary_embedding_size=20\n",
    "\n",
    "essay_vocab_size=30000\n",
    "essay_sentence_size=200\n",
    "essay_embedding_size=50\n",
    "pad_id=0\n",
    "\n",
    "\n",
    "resource_df = pd.read_csv(resource_file)\n",
    "groups = resource_df[['id','description']].groupby('id', as_index=False)\n",
    "\n",
    "id_column = []\n",
    "desc_column = []\n",
    "for name, group in groups:\n",
    "    id_column.append(name)\n",
    "\n",
    "    desc = ' '.join(str(k) if type(k)==int or type(k)==float else k for k in group['description'].values)\n",
    "    desc_column.append(desc)\n",
    "    \n",
    "desc_df = pd.DataFrame({\n",
    "    \"id\":id_column,\n",
    "    \"description\": desc_column\n",
    "})\n",
    "\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp84lnldo3\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp84lnldo3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x163361be0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "project_resource_summary text_2_vec data shape: (29997, 50)\n",
      "description text_2_vec data shape: (29997, 100)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp84lnldo3/model.ckpt.\n",
      "INFO:tensorflow:loss = 420.5515, step = 1\n",
      "INFO:tensorflow:global_step/sec: 56.4224\n",
      "INFO:tensorflow:loss = 37.42174, step = 101 (1.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0135\n",
      "INFO:tensorflow:loss = 36.86101, step = 201 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8517\n",
      "INFO:tensorflow:loss = 34.427986, step = 301 (1.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7445\n",
      "INFO:tensorflow:loss = 43.191643, step = 401 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.2525\n",
      "INFO:tensorflow:loss = 43.253006, step = 501 (1.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.2364\n",
      "INFO:tensorflow:loss = 42.42558, step = 601 (1.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.065\n",
      "INFO:tensorflow:loss = 27.779875, step = 701 (1.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.6653\n",
      "INFO:tensorflow:loss = 43.548138, step = 801 (1.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.5634\n",
      "INFO:tensorflow:loss = 48.28619, step = 901 (1.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.2979\n",
      "INFO:tensorflow:loss = 39.118763, step = 1001 (1.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.423\n",
      "INFO:tensorflow:loss = 35.031593, step = 1101 (1.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8891\n",
      "INFO:tensorflow:loss = 32.542377, step = 1201 (1.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9307\n",
      "INFO:tensorflow:loss = 39.406986, step = 1301 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7952\n",
      "INFO:tensorflow:loss = 38.749928, step = 1401 (1.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.312\n",
      "INFO:tensorflow:loss = 37.204926, step = 1501 (1.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0496\n",
      "INFO:tensorflow:loss = 51.008846, step = 1601 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.1402\n",
      "INFO:tensorflow:loss = 40.213882, step = 1701 (1.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9661\n",
      "INFO:tensorflow:loss = 36.33029, step = 1801 (1.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.4806\n",
      "INFO:tensorflow:loss = 26.291351, step = 1901 (1.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0399\n",
      "INFO:tensorflow:loss = 42.248287, step = 2001 (1.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.5536\n",
      "INFO:tensorflow:loss = 39.397446, step = 2101 (1.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.6172\n",
      "INFO:tensorflow:loss = 35.785275, step = 2201 (1.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9768\n",
      "INFO:tensorflow:loss = 31.631847, step = 2301 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.1273\n",
      "INFO:tensorflow:loss = 46.161697, step = 2401 (1.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.1458\n",
      "INFO:tensorflow:loss = 34.850975, step = 2501 (1.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7454\n",
      "INFO:tensorflow:loss = 30.02994, step = 2601 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.4879\n",
      "INFO:tensorflow:loss = 32.872902, step = 2701 (1.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.5758\n",
      "INFO:tensorflow:loss = 41.86939, step = 2801 (1.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3561\n",
      "INFO:tensorflow:loss = 25.483027, step = 2901 (1.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.1371\n",
      "INFO:tensorflow:loss = 42.698116, step = 3001 (1.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3698\n",
      "INFO:tensorflow:loss = 42.278233, step = 3101 (1.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9959\n",
      "INFO:tensorflow:loss = 32.15009, step = 3201 (1.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.6765\n",
      "INFO:tensorflow:loss = 41.26816, step = 3301 (1.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.125\n",
      "INFO:tensorflow:loss = 40.282192, step = 3401 (1.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.7235\n",
      "INFO:tensorflow:loss = 35.70732, step = 3501 (1.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.1623\n",
      "INFO:tensorflow:loss = 41.30201, step = 3601 (1.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0516\n",
      "INFO:tensorflow:loss = 38.68185, step = 3701 (1.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.2446\n",
      "INFO:tensorflow:loss = 47.90808, step = 3801 (1.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.7124\n",
      "INFO:tensorflow:loss = 38.675144, step = 3901 (1.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.8137\n",
      "INFO:tensorflow:loss = 39.490734, step = 4001 (1.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.7096\n",
      "INFO:tensorflow:loss = 38.192093, step = 4101 (1.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.4443\n",
      "INFO:tensorflow:loss = 40.0599, step = 4201 (1.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.233\n",
      "INFO:tensorflow:loss = 39.814068, step = 4301 (1.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.0243\n",
      "INFO:tensorflow:loss = 37.985752, step = 4401 (1.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.9285\n",
      "INFO:tensorflow:loss = 43.14182, step = 4501 (1.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5778\n",
      "INFO:tensorflow:loss = 30.175968, step = 4601 (1.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5551\n",
      "INFO:tensorflow:loss = 34.714214, step = 4701 (1.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.7852\n",
      "INFO:tensorflow:loss = 44.417816, step = 4801 (1.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.6761\n",
      "INFO:tensorflow:loss = 45.13247, step = 4901 (1.180 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp84lnldo3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 34.411777.\n",
      "project_resource_summary text_2_vec data shape: (59997, 50)\n",
      "description text_2_vec data shape: (59997, 100)\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=False and num_threads > 1. This will create multiple threads, all reading the array/dataframe in order. If you want examples read in order, use one thread; if you want multiple threads, enable shuffling.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-07-11:13:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp84lnldo3/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-07-11:13:52\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8465757, accuracy_baseline = 0.84685904, auc = 0.6785106, auc_precision_recall = 0.91317433, average_loss = 0.40284556, global_step = 5000, label/mean = 0.84685904, loss = 40.282543, precision = 0.8470123, prediction/mean = 0.8519319, recall = 0.9993308\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp84lnldo3/model.ckpt-5000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "accuracy: 0.8465757\n",
      "accuracy_baseline: 0.84685904\n",
      "auc: 0.6785106\n",
      "auc_precision_recall: 0.91317433\n",
      "average_loss: 0.40284556\n",
      "global_step: 5000\n",
      "label/mean: 0.84685904\n",
      "loss: 40.282543\n",
      "precision: 0.8470123\n",
      "prediction/mean: 0.8519319\n",
      "recall: 0.9993308\n"
     ]
    }
   ],
   "source": [
    "teacher_id = tf.feature_column.categorical_column_with_hash_bucket('teacher_id', hash_bucket_size=1000)\n",
    "\n",
    "project_title = tf.feature_column.categorical_column_with_hash_bucket('project_title', hash_bucket_size=5000)\n",
    "\n",
    "teacher_prefix = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"teacher_prefix\", [\n",
    "        \"Mrs.\",\"Ms.\",\"Mr.\",\"Teacher\",\"Dr.\"\n",
    "    ])\n",
    "teacher_prefix_bins = tf.feature_column.numeric_column('teacher_prefix_bins')\n",
    "\n",
    "school_state = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"school_state\",[\n",
    "        \"AK\",\"AL\",\"AR\",\"AZ\",\"CA\",\"CO\",\"CT\",\"DC\",\"DE\",\"FL\",\"GA\",\"HI\",\"IA\",\"ID\",\"IL\",\n",
    "        \"IN\",\"KS\",\"KY\",\"LA\",\"MA\",\"MD\",\"ME\",\"MI\",\"MN\",\"MO\",\"MS\",\"MT\",\"NC\",\"ND\",\"NE\",\n",
    "        \"NH\",\"NJ\",\"NM\",\"NV\",\"NY\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\n",
    "        \"TX\",\"UT\",\"VA\",\"VT\",\"WA\",\"WI\",\"WV\",\"WY\"\n",
    "    ])\n",
    "school_state_bins = tf.feature_column.numeric_column('school_state_bins')\n",
    "\n",
    "project_grade_category = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_grade_category\",[\"Grades 3-5\",\"Grades 6-8\",\"Grades 9-12\",\"Grades PreK-2\"])\n",
    "project_grade_category_bins = tf.feature_column.numeric_column('project_grade_category_bins')\n",
    "\n",
    "project_subject_categories = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_subject_categories\",[\n",
    "       \"Applied Learning\",\"Health & Sports\",\"History & Civics\",\"Literacy & Language\",\n",
    "        \"Math & Science\",\"Music & The Arts\",\"Special Needs\",\"Warmth\"])\n",
    "project_subject_categories_bins = tf.feature_column.numeric_column('project_subject_categories_bins')\n",
    "\n",
    "project_subject_subcategories = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_subject_subcategories\",[\n",
    "        \"Applied Learning\",\"Care & Hunger\",\"Health & Sports\",\"History & Civics\",\n",
    "        \"Literacy & Language\",\"Math & Science\",\"Music & The Arts\",\n",
    "        \"Warmth\",\"Applied Sciences\",\"Character Education\",\"Civics & Government\",\n",
    "        \"College & Career Prep\",\"Community Service\",\"ESL\",\"Early Development\",\n",
    "        \"Economics\",\"Environmental Science\",\"Extracurricular\",\"Financial Literacy\",\n",
    "        \"Foreign Languages\",\"Gym & Fitness\",\"Health & Life Science\",\"Health & Wellness\",\n",
    "        \"History & Geography\",\"Literacy\",\"Literature & Writing\",\"Mathematics\",\"Music\",\n",
    "        \"Nutrition Education\",\"Other\",\"Parent Involvement\",\"Performing Arts\",\n",
    "        \"Social Sciences\",\"Special Needs\",\"Team Sports\",\"Visual Arts\"])\n",
    "project_subject_subcategories_bins = tf.feature_column.numeric_column('project_subject_subcategories_bins')\n",
    "\n",
    "posted_projects = tf.feature_column.numeric_column('teacher_number_of_previously_posted_projects')\n",
    "posted_projects_bins = tf.feature_column.numeric_column('posted_projects_bins')\n",
    "\n",
    "quantity = tf.feature_column.numeric_column('quantity')\n",
    "price = tf.feature_column.numeric_column('price')\n",
    "avgPrice = tf.feature_column.numeric_column('avgPrice')\n",
    "\n",
    "\n",
    "#################### Text columns #########################\n",
    "summary_vec = tf.feature_column.categorical_column_with_identity('project_resource_summary_vec', summary_vocab_size)\n",
    "description_vec = tf.feature_column.categorical_column_with_identity('description_vec', summary_vocab_size)\n",
    "\n",
    "basic_columns = [\n",
    "\n",
    "]\n",
    "\n",
    "crossed_columns = [\n",
    "    tf.feature_column.crossed_column(['teacher_prefix', 'school_state'],\n",
    "                                    hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['school_state', 'project_grade_category'],\n",
    "                                    hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['project_grade_category', 'project_subject_categories'],\n",
    "                                    hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['project_subject_categories', 'project_subject_subcategories'],\n",
    "                                   hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['project_subject_categories', 'posted_projects_bins'],\n",
    "                                   hash_bucket_size=10000)\n",
    "]\n",
    "deep_columns = [\n",
    "    teacher_prefix_bins,\n",
    "    school_state_bins,\n",
    "    posted_projects,\n",
    "    project_grade_category_bins,\n",
    "    project_subject_categories_bins,\n",
    "    project_subject_subcategories_bins,\n",
    "    posted_projects_bins,\n",
    "    quantity,\n",
    "    price,\n",
    "    avgPrice,\n",
    "        \n",
    "    tf.feature_column.indicator_column(teacher_id),\n",
    "    tf.feature_column.indicator_column(project_title),\n",
    "    tf.feature_column.indicator_column(teacher_prefix),\n",
    "    tf.feature_column.indicator_column(school_state),\n",
    "    tf.feature_column.indicator_column(project_grade_category),\n",
    "    tf.feature_column.indicator_column(project_subject_categories),\n",
    "    tf.feature_column.indicator_column(project_subject_subcategories),\n",
    "    \n",
    "    tf.feature_column.embedding_column(summary_vec, dimension=summary_embedding_size),\n",
    "    tf.feature_column.embedding_column(description_vec, dimension=20),\n",
    "]\n",
    "\n",
    "def mix_operation(a, b):\n",
    "    return str(a) + '_' + str(b)\n",
    "\n",
    "def text_2_vec(feature_name, data_set, vocab_size, sentence_size):\n",
    "    texts = data_set[feature_name].values\n",
    "    \n",
    "    tokenizer = Tokenizer(vocab_size)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequence_data = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    data = sequence.pad_sequences(sequence_data, \n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "    print(feature_name + \" text_2_vec data shape:\", data.shape)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def build_input_features_dict(input_df):\n",
    "    features = {}\n",
    "    features['teacher_id'] = input_df['teacher_id'].values\n",
    "    \n",
    "    features['project_title'] = input_df['project_title'].values\n",
    "    \n",
    "    features['teacher_prefix'] = input_df['teacher_prefix'].values\n",
    "    features['teacher_prefix_bins'] = input_df['teacher_prefix_bins'].values\n",
    "    \n",
    "    features['school_state'] = input_df['school_state'].values\n",
    "    features['school_state_bins'] = input_df['school_state_bins'].values\n",
    "    \n",
    "    features['project_grade_category'] = input_df['project_grade_category'].values\n",
    "    features['project_grade_category_bins'] = input_df['project_grade_category_bins'].values\n",
    "\n",
    "    features['project_subject_categories'] = input_df['project_subject_categories'].values\n",
    "    features['project_subject_categories_bins'] = input_df['project_subject_categories_bins'].values\n",
    "\n",
    "    features['project_subject_subcategories'] = input_df['project_subject_subcategories'].values\n",
    "    features['project_subject_subcategories_bins'] = input_df['project_subject_subcategories_bins'].values\n",
    "    \n",
    "    features['teacher_number_of_previously_posted_projects'] = input_df['teacher_number_of_previously_posted_projects'].values\n",
    "    features['posted_projects_bins'] = input_df['posted_projects_bins'].values\n",
    "    \n",
    "    features['quantity'] = input_df['quantity'].values\n",
    "    features['price'] = input_df['price'].values\n",
    "    features['avgPrice'] = input_df['price']/input_df['quantity']\n",
    "    \n",
    "    #---  Text columns  ---#\n",
    "    features['project_resource_summary_vec'] = text_2_vec('project_resource_summary',input_df, \n",
    "                                                          summary_vocab_size,summary_sentence_size)\n",
    "    features['description_vec'] = text_2_vec('description',input_df, summary_vocab_size, 100)\n",
    "    #--- Text columns  ---#\n",
    "    \n",
    "    return features\n",
    "\n",
    "def input_fn(file, num_epochs, shuffle):\n",
    "    input_df = pd.read_csv(\n",
    "        tf.gfile.Open(file),names=CSV_COLUMNS,\n",
    "        skipinitialspace=True,engine=\"python\",skiprows=1)\n",
    "    resource_df = pd.read_csv(\n",
    "        tf.gfile.Open(resource_file),names=RESOURCE_COLUMNS,\n",
    "        skipinitialspace=True,engine=\"python\",skiprows=1)\n",
    "    \n",
    "    \n",
    "    input_df.dropna(subset=[\"teacher_prefix\"], inplace=True)\n",
    "    input_df['teacher_prefix_bins'] = label.fit_transform(input_df['teacher_prefix'])\n",
    "\n",
    "    input_df['school_state_bins'] = label.fit_transform(input_df['school_state'])\n",
    "    input_df['project_grade_category_bins'] = label.fit_transform(input_df['project_grade_category'])\n",
    "    input_df['project_subject_categories_bins'] = label.fit_transform(input_df['project_subject_categories'])\n",
    "    input_df['project_subject_subcategories_bins'] = label.fit_transform(input_df['project_subject_subcategories'])\n",
    "    \n",
    "    input_df['posted_projects_periods'] = pd.cut(input_df['teacher_number_of_previously_posted_projects'], \n",
    "                                                 [-1,7,50,1000])\n",
    "    input_df['posted_projects_bins'] = label.fit_transform(input_df['posted_projects_periods'])\n",
    "    \n",
    "    total_quantity_df = resource_df[['id','quantity']].groupby('id', as_index=False).sum()\n",
    "    total_price_df = resource_df[['id','price']].groupby('id', as_index=False).sum()\n",
    "\n",
    "    \n",
    "#     add quantity column, price column and divided of both columns from resource file into input_df \n",
    "    input_df = pd.merge(input_df, total_quantity_df, how='inner', on='id')\n",
    "    input_df = pd.merge(input_df, total_price_df, how='inner', on='id')\n",
    "    input_df = pd.merge(input_df, desc_df, how='inner', on='id')\n",
    "\n",
    "     \n",
    "    features = build_input_features_dict(input_df)\n",
    "    labels = input_df[target].values\n",
    "    \n",
    "    return tf.estimator.inputs.numpy_input_fn(features,\n",
    "                                              labels,\n",
    "                                              batch_size=100,\n",
    "                                              num_epochs=num_epochs,\n",
    "                                              shuffle=shuffle,\n",
    "                                              num_threads=8)\n",
    "\n",
    "def buildClassifier():\n",
    "    m = tf.estimator.DNNLinearCombinedClassifier(\n",
    "        linear_feature_columns = basic_columns + crossed_columns,\n",
    "        dnn_feature_columns = deep_columns,\n",
    "        dnn_hidden_units=[100])\n",
    "    return m\n",
    "    \n",
    "def train_and_evaluate():\n",
    "    classifier = buildClassifier()\n",
    "\n",
    "    classifier.train(input_fn=input_fn(train_file, num_epochs=None, shuffle=True), \n",
    "                     steps = 5000)\n",
    "    results = classifier.evaluate(input_fn=input_fn(eval_file, num_epochs=1, shuffle=False),\n",
    "                                      steps=None)\n",
    "    \n",
    "    print('-'*100)\n",
    "    for key in sorted(results):\n",
    "        print(\"%s: %s\" % (key, results[key]))\n",
    "        \n",
    "        \n",
    "    \n",
    "train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([p['logistic'][0] for p in classifier.predict(\n",
    "    input_fn=input_fn(test_file, num_epochs=1, shuffle=False))])\n",
    "\n",
    "print(predictions[:10])\n",
    "\n",
    "predict_result = pd.DataFrame({\n",
    "    \"id\":test_data['id'],\n",
    "    \"project_is_approved\":predictions\n",
    "})\n",
    "predict_result.to_csv('prince_DNN_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
