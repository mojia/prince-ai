{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p000001</td>\n",
       "      <td>Cap Barbell 300 Pound Olympic Set, Grey Cap Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p000002</td>\n",
       "      <td>10 Sony Headphones (BUY 9 GET 1 FREE) Belkin 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p000003</td>\n",
       "      <td>EE820X - Phonemic Awareness Instant Learning C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p000004</td>\n",
       "      <td>A Bad Case of the Giggles Poems That Will Make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p000005</td>\n",
       "      <td>Fitbit Zip Wireless Activity Tracker, Lime Fit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description\n",
       "0  p000001  Cap Barbell 300 Pound Olympic Set, Grey Cap Ba...\n",
       "1  p000002  10 Sony Headphones (BUY 9 GET 1 FREE) Belkin 6...\n",
       "2  p000003  EE820X - Phonemic Awareness Instant Learning C...\n",
       "3  p000004  A Bad Case of the Giggles Poems That Will Make...\n",
       "4  p000005  Fitbit Zip Wireless Activity Tracker, Lime Fit..."
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard import summary as summary_lib\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "dir='/Users/xinwang/ai/dataset/kaggle/DonorsChoose/'\n",
    "train_file = dir + 'train.csv'\n",
    "test_file = dir + 'test.csv'\n",
    "resource_file = dir + 'resources.csv'\n",
    "model_dir = \"/Users/xinwang/Downloads/models_temp/\"\n",
    "label = LabelEncoder()\n",
    "\n",
    "CSV_COLUMNS = ['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
    "       'project_submitted_datetime', 'project_grade_category',\n",
    "       'project_subject_categories', 'project_subject_subcategories',\n",
    "       'project_title', 'project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
    "       'teacher_number_of_previously_posted_projects', 'project_is_approved']\n",
    "TEST_CSV_COLUMNS = ['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
    "       'project_submitted_datetime', 'project_grade_category',\n",
    "       'project_subject_categories', 'project_subject_subcategories',\n",
    "       'project_title', 'project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
    "       'teacher_number_of_previously_posted_projects']\n",
    "RESOURCE_COLUMNS = ['id', 'description', 'quantity', 'price']\n",
    "target = 'project_is_approved'\n",
    "\n",
    "Train_Mode = 'train'\n",
    "Eval_Mode = 'eval'\n",
    "Test_Mode = 'test'\n",
    "\n",
    "positive_sample_size=5000\n",
    "negative_sample_size=5000\n",
    "\n",
    "summary_vocab_size=10000\n",
    "summary_sentence_size=50\n",
    "summary_embedding_size=20\n",
    "\n",
    "essay_vocab_size=30000\n",
    "essay_sentence_size=200\n",
    "essay_embedding_size=50\n",
    "pad_id=0\n",
    "\n",
    "\n",
    "resource_df = pd.read_csv(resource_file)\n",
    "groups = resource_df[['id','description']].groupby('id', as_index=False)\n",
    "\n",
    "id_column = []\n",
    "desc_column = []\n",
    "for name, group in groups:\n",
    "    id_column.append(name)\n",
    "\n",
    "    desc = ' '.join(str(k) if type(k)==int or type(k)==float else k for k in group['description'].values)\n",
    "    desc_column.append(desc)\n",
    "    \n",
    "desc_df = pd.DataFrame({\n",
    "    \"id\":id_column,\n",
    "    \"description\": desc_column\n",
    "})\n",
    "\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile done\n"
     ]
    }
   ],
   "source": [
    "SEED = 100\n",
    "train_epoches = 5000\n",
    "hidden_layers = [100, 50, 100, 50]\n",
    "\n",
    "teacher_id = tf.feature_column.categorical_column_with_hash_bucket('teacher_id', hash_bucket_size=1000)\n",
    "\n",
    "project_title = tf.feature_column.categorical_column_with_hash_bucket('project_title', hash_bucket_size=5000)\n",
    "\n",
    "teacher_prefix = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"teacher_prefix\", [\n",
    "        \"Mrs.\",\"Ms.\",\"Mr.\",\"Teacher\",\"Dr.\"\n",
    "    ])\n",
    "teacher_prefix_bins = tf.feature_column.numeric_column('teacher_prefix_bins')\n",
    "\n",
    "school_state = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"school_state\",[\n",
    "        \"AK\",\"AL\",\"AR\",\"AZ\",\"CA\",\"CO\",\"CT\",\"DC\",\"DE\",\"FL\",\"GA\",\"HI\",\"IA\",\"ID\",\"IL\",\n",
    "        \"IN\",\"KS\",\"KY\",\"LA\",\"MA\",\"MD\",\"ME\",\"MI\",\"MN\",\"MO\",\"MS\",\"MT\",\"NC\",\"ND\",\"NE\",\n",
    "        \"NH\",\"NJ\",\"NM\",\"NV\",\"NY\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\n",
    "        \"TX\",\"UT\",\"VA\",\"VT\",\"WA\",\"WI\",\"WV\",\"WY\"\n",
    "    ])\n",
    "school_state_bins = tf.feature_column.numeric_column('school_state_bins')\n",
    "\n",
    "project_grade_category = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_grade_category\",[\"Grades 3-5\",\"Grades 6-8\",\"Grades 9-12\",\"Grades PreK-2\"])\n",
    "project_grade_category_bins = tf.feature_column.numeric_column('project_grade_category_bins')\n",
    "\n",
    "project_subject_categories = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_subject_categories\",[\n",
    "       \"Applied Learning\",\"Health & Sports\",\"History & Civics\",\"Literacy & Language\",\n",
    "        \"Math & Science\",\"Music & The Arts\",\"Special Needs\",\"Warmth\"])\n",
    "project_subject_categories_bins = tf.feature_column.numeric_column('project_subject_categories_bins')\n",
    "\n",
    "project_subject_subcategories = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_subject_subcategories\",[\n",
    "        \"Applied Learning\",\"Care & Hunger\",\"Health & Sports\",\"History & Civics\",\n",
    "        \"Literacy & Language\",\"Math & Science\",\"Music & The Arts\",\n",
    "        \"Warmth\",\"Applied Sciences\",\"Character Education\",\"Civics & Government\",\n",
    "        \"College & Career Prep\",\"Community Service\",\"ESL\",\"Early Development\",\n",
    "        \"Economics\",\"Environmental Science\",\"Extracurricular\",\"Financial Literacy\",\n",
    "        \"Foreign Languages\",\"Gym & Fitness\",\"Health & Life Science\",\"Health & Wellness\",\n",
    "        \"History & Geography\",\"Literacy\",\"Literature & Writing\",\"Mathematics\",\"Music\",\n",
    "        \"Nutrition Education\",\"Other\",\"Parent Involvement\",\"Performing Arts\",\n",
    "        \"Social Sciences\",\"Special Needs\",\"Team Sports\",\"Visual Arts\"])\n",
    "project_subject_subcategories_bins = tf.feature_column.numeric_column('project_subject_subcategories_bins')\n",
    "\n",
    "posted_projects = tf.feature_column.numeric_column('teacher_number_of_previously_posted_projects')\n",
    "posted_projects_bins = tf.feature_column.numeric_column('posted_projects_bins')\n",
    "\n",
    "quantity = tf.feature_column.numeric_column('quantity')\n",
    "price = tf.feature_column.numeric_column('price')\n",
    "avgPrice = tf.feature_column.numeric_column('avgPrice')\n",
    "\n",
    "\n",
    "#################### Text columns #########################\n",
    "summary_vec = tf.feature_column.categorical_column_with_identity('project_resource_summary_vec', summary_vocab_size)\n",
    "description_vec = tf.feature_column.categorical_column_with_identity('description_vec', summary_vocab_size)\n",
    "\n",
    "basic_columns = [\n",
    "\n",
    "]\n",
    "\n",
    "crossed_columns = [\n",
    "    tf.feature_column.crossed_column(['teacher_prefix', 'school_state'],\n",
    "                                    hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['school_state', 'project_grade_category'],\n",
    "                                    hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['project_grade_category', 'project_subject_categories'],\n",
    "                                    hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['project_subject_categories', 'project_subject_subcategories'],\n",
    "                                   hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['project_subject_categories', 'posted_projects_bins'],\n",
    "                                   hash_bucket_size=10000)\n",
    "]\n",
    "deep_columns = [\n",
    "    teacher_prefix_bins,\n",
    "    school_state_bins,\n",
    "    posted_projects,\n",
    "    project_grade_category_bins,\n",
    "    project_subject_categories_bins,\n",
    "    project_subject_subcategories_bins,\n",
    "    posted_projects_bins,\n",
    "    quantity,\n",
    "    price,\n",
    "    avgPrice,\n",
    "        \n",
    "    tf.feature_column.indicator_column(teacher_id),\n",
    "    tf.feature_column.indicator_column(project_title),\n",
    "    tf.feature_column.indicator_column(teacher_prefix),\n",
    "    tf.feature_column.indicator_column(school_state),\n",
    "    tf.feature_column.indicator_column(project_grade_category),\n",
    "    tf.feature_column.indicator_column(project_subject_categories),\n",
    "    tf.feature_column.indicator_column(project_subject_subcategories),\n",
    "    \n",
    "    tf.feature_column.embedding_column(summary_vec, dimension=summary_embedding_size),\n",
    "    tf.feature_column.embedding_column(description_vec, dimension=20),\n",
    "]\n",
    "\n",
    "def mix_operation(a, b):\n",
    "    return str(a) + '_' + str(b)\n",
    "\n",
    "def text_2_vec(feature_name, data_set, vocab_size, sentence_size):\n",
    "    texts = data_set[feature_name].values\n",
    "    \n",
    "    tokenizer = Tokenizer(vocab_size)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequence_data = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    data = sequence.pad_sequences(sequence_data, \n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "    print(feature_name + \" text_2_vec data shape:\", data.shape)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def build_input_features_dict(input_df):\n",
    "    features = {}\n",
    "    features['teacher_id'] = input_df['teacher_id'].values\n",
    "    \n",
    "    features['project_title'] = input_df['project_title'].values\n",
    "    \n",
    "    features['teacher_prefix'] = input_df['teacher_prefix'].values\n",
    "    features['teacher_prefix_bins'] = input_df['teacher_prefix_bins'].values\n",
    "    \n",
    "    features['school_state'] = input_df['school_state'].values\n",
    "    features['school_state_bins'] = input_df['school_state_bins'].values\n",
    "    \n",
    "    features['project_grade_category'] = input_df['project_grade_category'].values\n",
    "    features['project_grade_category_bins'] = input_df['project_grade_category_bins'].values\n",
    "\n",
    "    features['project_subject_categories'] = input_df['project_subject_categories'].values\n",
    "    features['project_subject_categories_bins'] = input_df['project_subject_categories_bins'].values\n",
    "\n",
    "    features['project_subject_subcategories'] = input_df['project_subject_subcategories'].values\n",
    "    features['project_subject_subcategories_bins'] = input_df['project_subject_subcategories_bins'].values\n",
    "    \n",
    "    features['teacher_number_of_previously_posted_projects'] = input_df['teacher_number_of_previously_posted_projects'].values\n",
    "    features['posted_projects_bins'] = input_df['posted_projects_bins'].values\n",
    "    \n",
    "    features['quantity'] = input_df['quantity'].values\n",
    "    features['price'] = input_df['price'].values\n",
    "    features['avgPrice'] = input_df['price']/input_df['quantity']\n",
    "    \n",
    "    #---  Text columns  ---#\n",
    "    features['project_resource_summary_vec'] = text_2_vec('project_resource_summary',input_df, \n",
    "                                                          summary_vocab_size,summary_sentence_size)\n",
    "    features['description_vec'] = text_2_vec('description',input_df, summary_vocab_size, 100)\n",
    "    #--- Text columns  ---#\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def balanceData(df):\n",
    "    label_1_df = df[df['project_is_approved']==1].sample(n=positive_sample_size, random_state=SEED)\n",
    "    label_0_df = df[df['project_is_approved']==0].sample(n=negative_sample_size, random_state=SEED)\n",
    "\n",
    "    data_set = pd.concat([label_1_df,label_0_df])\n",
    "    data_set = shuffle(data_set)\n",
    "    \n",
    "    return data_set\n",
    "\n",
    "\n",
    "all_df = pd.read_csv(\n",
    "        tf.gfile.Open(train_file),names=CSV_COLUMNS,\n",
    "        skipinitialspace=True,engine=\"python\",skiprows=1)\n",
    "balance_df = balanceData(all_df)\n",
    "\n",
    "train_df = balance_df.sample(frac=0.8, random_state=SEED)\n",
    "eval_df = balance_df.drop(train_df.index)\n",
    "def build_input_df(file, mode):\n",
    "    if mode == Test_Mode:\n",
    "        test_df = pd.read_csv(tf.gfile.Open(test_file),names=TEST_CSV_COLUMNS,\n",
    "                              skipinitialspace=True,engine=\"python\",skiprows=1)\n",
    "        \n",
    "        print('get Test Mode dataset', test_df.shape)\n",
    "        return test_df\n",
    "    elif mode == Eval_Mode:\n",
    "        print('get Eval Mode dataset', eval_df.shape)\n",
    "        return eval_df\n",
    "    else:\n",
    "        print('get Train Mode dataset', train_df.shape)\n",
    "        return train_df\n",
    "\n",
    "def input_fn(file, mode, num_epochs, shuffle):\n",
    "    input_df = build_input_df(file, mode)\n",
    "    resource_df = pd.read_csv(\n",
    "        tf.gfile.Open(resource_file),names=RESOURCE_COLUMNS,\n",
    "        skipinitialspace=True,engine=\"python\",skiprows=1)\n",
    "    \n",
    "    input_df.fillna(value={\"teacher_prefix\":'Mr.'}, inplace=True)\n",
    "    input_df['teacher_prefix_bins'] = label.fit_transform(input_df['teacher_prefix'])\n",
    "\n",
    "    input_df['school_state_bins'] = label.fit_transform(input_df['school_state'])\n",
    "    input_df['project_grade_category_bins'] = label.fit_transform(input_df['project_grade_category'])\n",
    "    input_df['project_subject_categories_bins'] = label.fit_transform(input_df['project_subject_categories'])\n",
    "    input_df['project_subject_subcategories_bins'] = label.fit_transform(input_df['project_subject_subcategories'])\n",
    "    \n",
    "    input_df['posted_projects_periods'] = pd.cut(input_df['teacher_number_of_previously_posted_projects'], \n",
    "                                                 [-1,7,50,1000])\n",
    "    input_df['posted_projects_bins'] = label.fit_transform(input_df['posted_projects_periods'])\n",
    "    \n",
    "    total_quantity_df = resource_df[['id','quantity']].groupby('id', as_index=False).sum()\n",
    "    total_price_df = resource_df[['id','price']].groupby('id', as_index=False).sum()\n",
    "\n",
    "    \n",
    "#   add quantity column, price column and divided of both columns from resource file into input_df \n",
    "    input_df = pd.merge(input_df, total_quantity_df, how='inner', on='id')\n",
    "    input_df = pd.merge(input_df, total_price_df, how='inner', on='id')\n",
    "    input_df = pd.merge(input_df, desc_df, how='inner', on='id')\n",
    "\n",
    "     \n",
    "    features = build_input_features_dict(input_df)\n",
    "\n",
    "    length = len(input_df.iloc[:, 1])\n",
    "    print(mode + ' dataset length',length)\n",
    "    \n",
    "    threads = 8\n",
    "    if mode == Test_Mode:\n",
    "        input_df.info()\n",
    "        labels = np.empty([length,1])\n",
    "        threads = 1\n",
    "    else:\n",
    "        input_df.info()\n",
    "        labels = input_df[target].values\n",
    "    \n",
    "    print(mode + ' labels size:' + str(len(labels)))\n",
    "    \n",
    "    \n",
    "    return tf.estimator.inputs.numpy_input_fn(features,\n",
    "                                              labels,\n",
    "                                              batch_size=100,\n",
    "                                              num_epochs=num_epochs,\n",
    "                                              shuffle=shuffle,\n",
    "                                              num_threads=threads)\n",
    "\n",
    "def buildClassifier():\n",
    "    m = tf.estimator.DNNLinearCombinedClassifier(\n",
    "        linear_feature_columns = basic_columns + crossed_columns,\n",
    "        dnn_feature_columns = deep_columns,\n",
    "        dnn_hidden_units=hidden_layers,\n",
    "        dnn_activation_fn=tf.nn.relu6,\n",
    "        dnn_dropout=0.4)\n",
    "    return m\n",
    "    \n",
    "def train_and_evaluate():\n",
    "    classifier = buildClassifier()\n",
    "\n",
    "    classifier.train(input_fn=input_fn(train_file, Train_Mode, num_epochs=None, shuffle=True), \n",
    "                     steps = train_epoches)\n",
    "    results = classifier.evaluate(input_fn=input_fn(train_file, Eval_Mode, num_epochs=1, shuffle=False),\n",
    "                                      steps=None)\n",
    "    \n",
    "    print('-'*100)\n",
    "    for key in sorted(results):\n",
    "        print(\"%s: %s\" % (key, results[key]))\n",
    "        \n",
    "    \n",
    "    return classifier\n",
    "\n",
    "\n",
    "print('compile done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpirtda76l\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpirtda76l', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13d24d208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "get Train Mode dataset (45600, 16)\n",
      "project_resource_summary text_2_vec data shape: (45600, 50)\n",
      "description text_2_vec data shape: (45600, 100)\n",
      "train dataset length 45600\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45600 entries, 0 to 45599\n",
      "Data columns (total 26 columns):\n",
      "id                                              45600 non-null object\n",
      "teacher_id                                      45600 non-null object\n",
      "teacher_prefix                                  45600 non-null object\n",
      "school_state                                    45600 non-null object\n",
      "project_submitted_datetime                      45600 non-null object\n",
      "project_grade_category                          45600 non-null object\n",
      "project_subject_categories                      45600 non-null object\n",
      "project_subject_subcategories                   45600 non-null object\n",
      "project_title                                   45600 non-null object\n",
      "project_essay_1                                 45600 non-null object\n",
      "project_essay_2                                 45600 non-null object\n",
      "project_essay_3                                 1572 non-null object\n",
      "project_essay_4                                 1572 non-null object\n",
      "project_resource_summary                        45600 non-null object\n",
      "teacher_number_of_previously_posted_projects    45600 non-null int64\n",
      "project_is_approved                             45600 non-null int64\n",
      "teacher_prefix_bins                             45600 non-null int64\n",
      "school_state_bins                               45600 non-null int64\n",
      "project_grade_category_bins                     45600 non-null int64\n",
      "project_subject_categories_bins                 45600 non-null int64\n",
      "project_subject_subcategories_bins              45600 non-null int64\n",
      "posted_projects_periods                         45600 non-null category\n",
      "posted_projects_bins                            45600 non-null int64\n",
      "quantity                                        45600 non-null int64\n",
      "price                                           45600 non-null float64\n",
      "description                                     45600 non-null object\n",
      "dtypes: category(1), float64(1), int64(9), object(15)\n",
      "memory usage: 9.1+ MB\n",
      "train labels size:45600\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpirtda76l/model.ckpt.\n",
      "INFO:tensorflow:loss = 168.14313, step = 1\n",
      "INFO:tensorflow:global_step/sec: 47.5259\n",
      "INFO:tensorflow:loss = 85.61415, step = 101 (2.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.1935\n",
      "INFO:tensorflow:loss = 68.04895, step = 201 (1.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.2889\n",
      "INFO:tensorflow:loss = 75.49339, step = 301 (1.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.2797\n",
      "INFO:tensorflow:loss = 77.802475, step = 401 (1.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.8655\n",
      "INFO:tensorflow:loss = 74.96446, step = 501 (1.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1483\n",
      "INFO:tensorflow:loss = 76.19932, step = 601 (1.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.9702\n",
      "INFO:tensorflow:loss = 71.52524, step = 701 (1.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.8578\n",
      "INFO:tensorflow:loss = 74.59938, step = 801 (1.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2766\n",
      "INFO:tensorflow:loss = 66.32718, step = 901 (1.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0387\n",
      "INFO:tensorflow:loss = 70.048996, step = 1001 (1.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.5003\n",
      "INFO:tensorflow:loss = 72.13932, step = 1101 (1.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.1742\n",
      "INFO:tensorflow:loss = 67.93537, step = 1201 (1.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.1471\n",
      "INFO:tensorflow:loss = 71.33089, step = 1301 (1.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0614\n",
      "INFO:tensorflow:loss = 75.80279, step = 1401 (1.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.9455\n",
      "INFO:tensorflow:loss = 75.88097, step = 1501 (1.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.9453\n",
      "INFO:tensorflow:loss = 66.83718, step = 1601 (1.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.9936\n",
      "INFO:tensorflow:loss = 70.400566, step = 1701 (1.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.1881\n",
      "INFO:tensorflow:loss = 76.09317, step = 1801 (1.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.0289\n",
      "INFO:tensorflow:loss = 71.33536, step = 1901 (1.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.687\n",
      "INFO:tensorflow:loss = 73.368, step = 2001 (1.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.7767\n",
      "INFO:tensorflow:loss = 70.71669, step = 2101 (1.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.8165\n",
      "INFO:tensorflow:loss = 67.04522, step = 2201 (1.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.7896\n",
      "INFO:tensorflow:loss = 68.79796, step = 2301 (1.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.1509\n",
      "INFO:tensorflow:loss = 74.892265, step = 2401 (1.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.9036\n",
      "INFO:tensorflow:loss = 75.3785, step = 2501 (1.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.6241\n",
      "INFO:tensorflow:loss = 64.22046, step = 2601 (1.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.4335\n",
      "INFO:tensorflow:loss = 71.43084, step = 2701 (1.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.4764\n",
      "INFO:tensorflow:loss = 69.917206, step = 2801 (1.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.0737\n",
      "INFO:tensorflow:loss = 66.51252, step = 2901 (1.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.0496\n",
      "INFO:tensorflow:loss = 67.5979, step = 3001 (1.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.2618\n",
      "INFO:tensorflow:loss = 69.76588, step = 3101 (1.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.0862\n",
      "INFO:tensorflow:loss = 67.56166, step = 3201 (1.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.4911\n",
      "INFO:tensorflow:loss = 66.9884, step = 3301 (1.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3597\n",
      "INFO:tensorflow:loss = 66.8498, step = 3401 (1.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.1606\n",
      "INFO:tensorflow:loss = 68.566154, step = 3501 (1.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.4737\n",
      "INFO:tensorflow:loss = 71.171196, step = 3601 (1.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.951\n",
      "INFO:tensorflow:loss = 67.21958, step = 3701 (1.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.7913\n",
      "INFO:tensorflow:loss = 69.191765, step = 3801 (1.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.1878\n",
      "INFO:tensorflow:loss = 68.50306, step = 3901 (1.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.8335\n",
      "INFO:tensorflow:loss = 65.809525, step = 4001 (1.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0156\n",
      "INFO:tensorflow:loss = 66.78256, step = 4101 (1.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.917\n",
      "INFO:tensorflow:loss = 68.8201, step = 4201 (1.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.7339\n",
      "INFO:tensorflow:loss = 71.13399, step = 4301 (1.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.3883\n",
      "INFO:tensorflow:loss = 70.4588, step = 4401 (1.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.9631\n",
      "INFO:tensorflow:loss = 66.68532, step = 4501 (1.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.374\n",
      "INFO:tensorflow:loss = 72.68204, step = 4601 (1.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.7312\n",
      "INFO:tensorflow:loss = 68.85485, step = 4701 (1.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.3724\n",
      "INFO:tensorflow:loss = 64.49108, step = 4801 (1.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.8012\n",
      "INFO:tensorflow:loss = 71.118164, step = 4901 (1.393 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 72.0412\n",
      "INFO:tensorflow:loss = 67.65539, step = 5001 (1.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.549\n",
      "INFO:tensorflow:loss = 68.09361, step = 5101 (1.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.4766\n",
      "INFO:tensorflow:loss = 69.397644, step = 5201 (1.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.865\n",
      "INFO:tensorflow:loss = 65.21288, step = 5301 (1.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.8475\n",
      "INFO:tensorflow:loss = 72.94888, step = 5401 (1.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.642\n",
      "INFO:tensorflow:loss = 76.173744, step = 5501 (1.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.8403\n",
      "INFO:tensorflow:loss = 66.29588, step = 5601 (1.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.522\n",
      "INFO:tensorflow:loss = 70.17819, step = 5701 (1.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.7537\n",
      "INFO:tensorflow:loss = 68.528015, step = 5801 (1.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2724\n",
      "INFO:tensorflow:loss = 67.742065, step = 5901 (1.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.4391\n",
      "INFO:tensorflow:loss = 67.0462, step = 6001 (1.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.1658\n",
      "INFO:tensorflow:loss = 68.01092, step = 6101 (1.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.8553\n",
      "INFO:tensorflow:loss = 67.38145, step = 6201 (1.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1629\n",
      "INFO:tensorflow:loss = 69.87994, step = 6301 (2.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.0166\n",
      "INFO:tensorflow:loss = 67.88207, step = 6401 (1.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.9109\n",
      "INFO:tensorflow:loss = 68.86773, step = 6501 (1.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.2075\n",
      "INFO:tensorflow:loss = 69.36248, step = 6601 (1.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.3761\n",
      "INFO:tensorflow:loss = 64.689224, step = 6701 (1.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.307\n",
      "INFO:tensorflow:loss = 68.299965, step = 6801 (1.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.2752\n",
      "INFO:tensorflow:loss = 66.21409, step = 6901 (1.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.5428\n",
      "INFO:tensorflow:loss = 63.709213, step = 7001 (1.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.4129\n",
      "INFO:tensorflow:loss = 63.633026, step = 7101 (1.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.9225\n",
      "INFO:tensorflow:loss = 67.0914, step = 7201 (1.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.7494\n",
      "INFO:tensorflow:loss = 65.612305, step = 7301 (1.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.1318\n",
      "INFO:tensorflow:loss = 71.22651, step = 7401 (1.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.8046\n",
      "INFO:tensorflow:loss = 68.73972, step = 7501 (1.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.2408\n",
      "INFO:tensorflow:loss = 64.71852, step = 7601 (1.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.6577\n",
      "INFO:tensorflow:loss = 66.72059, step = 7701 (1.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.9446\n",
      "INFO:tensorflow:loss = 67.474556, step = 7801 (1.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.0611\n",
      "INFO:tensorflow:loss = 66.76924, step = 7901 (1.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.07\n",
      "INFO:tensorflow:loss = 70.536804, step = 8001 (1.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9275\n",
      "INFO:tensorflow:loss = 64.39997, step = 8101 (1.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.1823\n",
      "INFO:tensorflow:loss = 64.45744, step = 8201 (1.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.7277\n",
      "INFO:tensorflow:loss = 65.418884, step = 8301 (1.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.1941\n",
      "INFO:tensorflow:loss = 66.41488, step = 8401 (1.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.4091\n",
      "INFO:tensorflow:loss = 68.660645, step = 8501 (1.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.9348\n",
      "INFO:tensorflow:loss = 67.18205, step = 8601 (1.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.9139\n",
      "INFO:tensorflow:loss = 71.64014, step = 8701 (1.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.9877\n",
      "INFO:tensorflow:loss = 66.47009, step = 8801 (1.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.1963\n",
      "INFO:tensorflow:loss = 65.71222, step = 8901 (1.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.067\n",
      "INFO:tensorflow:loss = 70.185844, step = 9001 (1.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.0212\n",
      "INFO:tensorflow:loss = 67.2354, step = 9101 (1.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.427\n",
      "INFO:tensorflow:loss = 65.46919, step = 9201 (1.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.4087\n",
      "INFO:tensorflow:loss = 63.06823, step = 9301 (1.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.0376\n",
      "INFO:tensorflow:loss = 71.15184, step = 9401 (1.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.3086\n",
      "INFO:tensorflow:loss = 66.29558, step = 9501 (1.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.5862\n",
      "INFO:tensorflow:loss = 65.40196, step = 9601 (1.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.9206\n",
      "INFO:tensorflow:loss = 69.37719, step = 9701 (1.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3512\n",
      "INFO:tensorflow:loss = 66.66361, step = 9801 (1.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.6906\n",
      "INFO:tensorflow:loss = 67.27499, step = 9901 (1.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.7013\n",
      "INFO:tensorflow:loss = 66.23868, step = 10001 (1.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2681\n",
      "INFO:tensorflow:loss = 69.56143, step = 10101 (1.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.0706\n",
      "INFO:tensorflow:loss = 66.904236, step = 10201 (1.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.2759\n",
      "INFO:tensorflow:loss = 71.832634, step = 10301 (1.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.7985\n",
      "INFO:tensorflow:loss = 72.81219, step = 10401 (1.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.8097\n",
      "INFO:tensorflow:loss = 68.41336, step = 10501 (1.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.1942\n",
      "INFO:tensorflow:loss = 67.70595, step = 10601 (1.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5347\n",
      "INFO:tensorflow:loss = 67.16447, step = 10701 (1.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.0122\n",
      "INFO:tensorflow:loss = 66.46845, step = 10801 (1.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.2137\n",
      "INFO:tensorflow:loss = 66.955734, step = 10901 (1.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.4034\n",
      "INFO:tensorflow:loss = 66.912964, step = 11001 (1.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.9659\n",
      "INFO:tensorflow:loss = 63.555546, step = 11101 (1.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.956\n",
      "INFO:tensorflow:loss = 70.17923, step = 11201 (1.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.3552\n",
      "INFO:tensorflow:loss = 69.926506, step = 11301 (1.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.2231\n",
      "INFO:tensorflow:loss = 70.05164, step = 11401 (1.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.4035\n",
      "INFO:tensorflow:loss = 67.4334, step = 11501 (1.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.0349\n",
      "INFO:tensorflow:loss = 69.14335, step = 11601 (1.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5088\n",
      "INFO:tensorflow:loss = 68.19927, step = 11701 (1.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2633\n",
      "INFO:tensorflow:loss = 66.17411, step = 11801 (1.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.8687\n",
      "INFO:tensorflow:loss = 63.348396, step = 11901 (1.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7002\n",
      "INFO:tensorflow:loss = 66.25714, step = 12001 (1.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.4594\n",
      "INFO:tensorflow:loss = 70.11214, step = 12101 (1.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.0496\n",
      "INFO:tensorflow:loss = 63.655113, step = 12201 (1.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.88\n",
      "INFO:tensorflow:loss = 66.26321, step = 12301 (1.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.3019\n",
      "INFO:tensorflow:loss = 64.96268, step = 12401 (1.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.9961\n",
      "INFO:tensorflow:loss = 64.98167, step = 12501 (1.389 sec)\n"
     ]
    }
   ],
   "source": [
    "classifier = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get Test Mode dataset (78035, 15)\n",
      "project_resource_summary text_2_vec data shape: (78035, 50)\n",
      "description text_2_vec data shape: (78035, 100)\n",
      "test dataset length 78035\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78035 entries, 0 to 78034\n",
      "Data columns (total 25 columns):\n",
      "id                                              78035 non-null object\n",
      "teacher_id                                      78035 non-null object\n",
      "teacher_prefix                                  78035 non-null object\n",
      "school_state                                    78035 non-null object\n",
      "project_submitted_datetime                      78035 non-null object\n",
      "project_grade_category                          78035 non-null object\n",
      "project_subject_categories                      78035 non-null object\n",
      "project_subject_subcategories                   78035 non-null object\n",
      "project_title                                   78035 non-null object\n",
      "project_essay_1                                 78035 non-null object\n",
      "project_essay_2                                 78035 non-null object\n",
      "project_essay_3                                 2704 non-null object\n",
      "project_essay_4                                 2704 non-null object\n",
      "project_resource_summary                        78035 non-null object\n",
      "teacher_number_of_previously_posted_projects    78035 non-null int64\n",
      "teacher_prefix_bins                             78035 non-null int64\n",
      "school_state_bins                               78035 non-null int64\n",
      "project_grade_category_bins                     78035 non-null int64\n",
      "project_subject_categories_bins                 78035 non-null int64\n",
      "project_subject_subcategories_bins              78035 non-null int64\n",
      "posted_projects_periods                         78035 non-null category\n",
      "posted_projects_bins                            78035 non-null int64\n",
      "quantity                                        78035 non-null int64\n",
      "price                                           78035 non-null float64\n",
      "description                                     78035 non-null object\n",
      "dtypes: category(1), float64(1), int64(8), object(15)\n",
      "memory usage: 15.0+ MB\n",
      "test labels size:78035\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpxh19ngpz/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "predictions.shape (78035,)\n",
      "[0.6804151  0.67411816 0.62799746 0.48718554 0.4760771  0.4874223\n",
      " 0.673548   0.61403805 0.6106024  0.7294376 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinwang/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(input_fn= input_fn(test_file, Test_Mode, num_epochs=1, shuffle=False))\n",
    "\n",
    "predictions = np.array([p['logistic'][0] for p in result])\n",
    "\n",
    "print('predictions.shape', predictions.shape)\n",
    "print(predictions[:10])\n",
    "\n",
    "test_data = pd.read_csv(test_file)\n",
    "predict_result = pd.DataFrame({\n",
    "    \"id\":test_data['id'],\n",
    "    \"project_is_approved\":predictions\n",
    "})\n",
    "predict_result.to_csv('prince_DNN_submission.csv', index=False)\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
