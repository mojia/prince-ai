{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpvlw3nuot\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpvlw3nuot', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13df1a2b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "project_resource_summary text_2_vec data shape: (59997, 50)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpvlw3nuot/model.ckpt.\n",
      "INFO:tensorflow:loss = 228.5722, step = 1\n",
      "INFO:tensorflow:global_step/sec: 90.6811\n",
      "INFO:tensorflow:loss = 33.733055, step = 101 (1.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.321\n",
      "INFO:tensorflow:loss = 46.83617, step = 201 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.251\n",
      "INFO:tensorflow:loss = 35.805576, step = 301 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.215\n",
      "INFO:tensorflow:loss = 36.47441, step = 401 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.546\n",
      "INFO:tensorflow:loss = 44.03336, step = 501 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.108\n",
      "INFO:tensorflow:loss = 41.24616, step = 601 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.652\n",
      "INFO:tensorflow:loss = 49.239216, step = 701 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.601\n",
      "INFO:tensorflow:loss = 33.183388, step = 801 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.311\n",
      "INFO:tensorflow:loss = 48.466377, step = 901 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.296\n",
      "INFO:tensorflow:loss = 44.60014, step = 1001 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.946\n",
      "INFO:tensorflow:loss = 33.198174, step = 1101 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.527\n",
      "INFO:tensorflow:loss = 37.417118, step = 1201 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.93\n",
      "INFO:tensorflow:loss = 39.22584, step = 1301 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.421\n",
      "INFO:tensorflow:loss = 40.780746, step = 1401 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.903\n",
      "INFO:tensorflow:loss = 36.81224, step = 1501 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.232\n",
      "INFO:tensorflow:loss = 48.74912, step = 1601 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.484\n",
      "INFO:tensorflow:loss = 43.26536, step = 1701 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.858\n",
      "INFO:tensorflow:loss = 38.998768, step = 1801 (0.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.756\n",
      "INFO:tensorflow:loss = 38.71928, step = 1901 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.201\n",
      "INFO:tensorflow:loss = 37.341827, step = 2001 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.011\n",
      "INFO:tensorflow:loss = 34.52617, step = 2101 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.602\n",
      "INFO:tensorflow:loss = 46.65329, step = 2201 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.034\n",
      "INFO:tensorflow:loss = 35.251507, step = 2301 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.784\n",
      "INFO:tensorflow:loss = 45.094105, step = 2401 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.641\n",
      "INFO:tensorflow:loss = 48.264153, step = 2501 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.704\n",
      "INFO:tensorflow:loss = 52.64174, step = 2601 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.318\n",
      "INFO:tensorflow:loss = 57.564198, step = 2701 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.359\n",
      "INFO:tensorflow:loss = 35.70456, step = 2801 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.911\n",
      "INFO:tensorflow:loss = 37.00268, step = 2901 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.305\n",
      "INFO:tensorflow:loss = 29.738361, step = 3001 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.29\n",
      "INFO:tensorflow:loss = 34.736336, step = 3101 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.134\n",
      "INFO:tensorflow:loss = 39.840324, step = 3201 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.293\n",
      "INFO:tensorflow:loss = 37.363747, step = 3301 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.186\n",
      "INFO:tensorflow:loss = 42.803272, step = 3401 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.669\n",
      "INFO:tensorflow:loss = 36.636536, step = 3501 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.631\n",
      "INFO:tensorflow:loss = 44.454597, step = 3601 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.548\n",
      "INFO:tensorflow:loss = 43.22641, step = 3701 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.251\n",
      "INFO:tensorflow:loss = 43.697445, step = 3801 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.201\n",
      "INFO:tensorflow:loss = 37.98509, step = 3901 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.1\n",
      "INFO:tensorflow:loss = 42.123924, step = 4001 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.629\n",
      "INFO:tensorflow:loss = 37.5235, step = 4101 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.782\n",
      "INFO:tensorflow:loss = 36.771854, step = 4201 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.432\n",
      "INFO:tensorflow:loss = 38.92656, step = 4301 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.856\n",
      "INFO:tensorflow:loss = 44.09466, step = 4401 (0.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.106\n",
      "INFO:tensorflow:loss = 35.529175, step = 4501 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.051\n",
      "INFO:tensorflow:loss = 36.86255, step = 4601 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.726\n",
      "INFO:tensorflow:loss = 50.71828, step = 4701 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.435\n",
      "INFO:tensorflow:loss = 40.03727, step = 4801 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.684\n",
      "INFO:tensorflow:loss = 36.220005, step = 4901 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.184\n",
      "INFO:tensorflow:loss = 45.45616, step = 5001 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.919\n",
      "INFO:tensorflow:loss = 39.283165, step = 5101 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.143\n",
      "INFO:tensorflow:loss = 42.40754, step = 5201 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.652\n",
      "INFO:tensorflow:loss = 50.037857, step = 5301 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.351\n",
      "INFO:tensorflow:loss = 44.36162, step = 5401 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.987\n",
      "INFO:tensorflow:loss = 42.719116, step = 5501 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.79\n",
      "INFO:tensorflow:loss = 40.41529, step = 5601 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.301\n",
      "INFO:tensorflow:loss = 36.967194, step = 5701 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.195\n",
      "INFO:tensorflow:loss = 37.511375, step = 5801 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.507\n",
      "INFO:tensorflow:loss = 37.220863, step = 5901 (0.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.431\n",
      "INFO:tensorflow:loss = 39.861546, step = 6001 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.921\n",
      "INFO:tensorflow:loss = 32.311985, step = 6101 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.206\n",
      "INFO:tensorflow:loss = 40.14638, step = 6201 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.617\n",
      "INFO:tensorflow:loss = 43.689682, step = 6301 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.715\n",
      "INFO:tensorflow:loss = 33.6761, step = 6401 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.975\n",
      "INFO:tensorflow:loss = 42.631046, step = 6501 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.503\n",
      "INFO:tensorflow:loss = 33.575184, step = 6601 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.001\n",
      "INFO:tensorflow:loss = 39.55155, step = 6701 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.549\n",
      "INFO:tensorflow:loss = 37.8883, step = 6801 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.592\n",
      "INFO:tensorflow:loss = 28.362566, step = 6901 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.327\n",
      "INFO:tensorflow:loss = 47.27543, step = 7001 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 50.111202, step = 7101 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.125\n",
      "INFO:tensorflow:loss = 45.053425, step = 7201 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.679\n",
      "INFO:tensorflow:loss = 50.746544, step = 7301 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.145\n",
      "INFO:tensorflow:loss = 48.27339, step = 7401 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.511\n",
      "INFO:tensorflow:loss = 39.552845, step = 7501 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.157\n",
      "INFO:tensorflow:loss = 40.213913, step = 7601 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.122\n",
      "INFO:tensorflow:loss = 45.42902, step = 7701 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.742\n",
      "INFO:tensorflow:loss = 36.50221, step = 7801 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.224\n",
      "INFO:tensorflow:loss = 38.89965, step = 7901 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.028\n",
      "INFO:tensorflow:loss = 40.83607, step = 8001 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.178\n",
      "INFO:tensorflow:loss = 48.994255, step = 8101 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.205\n",
      "INFO:tensorflow:loss = 41.254692, step = 8201 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.183\n",
      "INFO:tensorflow:loss = 35.50358, step = 8301 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.301\n",
      "INFO:tensorflow:loss = 38.655495, step = 8401 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.05\n",
      "INFO:tensorflow:loss = 36.450623, step = 8501 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.478\n",
      "INFO:tensorflow:loss = 45.931087, step = 8601 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.089\n",
      "INFO:tensorflow:loss = 39.732502, step = 8701 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.542\n",
      "INFO:tensorflow:loss = 43.751663, step = 8801 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.152\n",
      "INFO:tensorflow:loss = 44.768684, step = 8901 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.255\n",
      "INFO:tensorflow:loss = 33.863834, step = 9001 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.33\n",
      "INFO:tensorflow:loss = 30.731468, step = 9101 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.395\n",
      "INFO:tensorflow:loss = 43.89145, step = 9201 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.611\n",
      "INFO:tensorflow:loss = 44.97379, step = 9301 (0.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.551\n",
      "INFO:tensorflow:loss = 46.29233, step = 9401 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.341\n",
      "INFO:tensorflow:loss = 35.47003, step = 9501 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.298\n",
      "INFO:tensorflow:loss = 43.997887, step = 9601 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.431\n",
      "INFO:tensorflow:loss = 35.783848, step = 9701 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.148\n",
      "INFO:tensorflow:loss = 44.952927, step = 9801 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.555\n",
      "INFO:tensorflow:loss = 40.786797, step = 9901 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.145\n",
      "INFO:tensorflow:loss = 62.910557, step = 10001 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.636\n",
      "INFO:tensorflow:loss = 51.073322, step = 10101 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.246\n",
      "INFO:tensorflow:loss = 50.573845, step = 10201 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.715\n",
      "INFO:tensorflow:loss = 37.997833, step = 10301 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.787\n",
      "INFO:tensorflow:loss = 38.811028, step = 10401 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.663\n",
      "INFO:tensorflow:loss = 39.91695, step = 10501 (0.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.868\n",
      "INFO:tensorflow:loss = 54.268875, step = 10601 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.772\n",
      "INFO:tensorflow:loss = 41.878654, step = 10701 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.73\n",
      "INFO:tensorflow:loss = 47.02967, step = 10801 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.534\n",
      "INFO:tensorflow:loss = 46.208893, step = 10901 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.103\n",
      "INFO:tensorflow:loss = 36.97002, step = 11001 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.199\n",
      "INFO:tensorflow:loss = 41.535526, step = 11101 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.953\n",
      "INFO:tensorflow:loss = 43.33104, step = 11201 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.776\n",
      "INFO:tensorflow:loss = 37.528618, step = 11301 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.243\n",
      "INFO:tensorflow:loss = 38.75608, step = 11401 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.534\n",
      "INFO:tensorflow:loss = 39.138737, step = 11501 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.032\n",
      "INFO:tensorflow:loss = 34.94738, step = 11601 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.476\n",
      "INFO:tensorflow:loss = 41.31712, step = 11701 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.534\n",
      "INFO:tensorflow:loss = 35.898388, step = 11801 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.93\n",
      "INFO:tensorflow:loss = 32.076855, step = 11901 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.772\n",
      "INFO:tensorflow:loss = 40.406235, step = 12001 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.302\n",
      "INFO:tensorflow:loss = 40.89758, step = 12101 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.524\n",
      "INFO:tensorflow:loss = 34.621506, step = 12201 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.062\n",
      "INFO:tensorflow:loss = 47.0339, step = 12301 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.649\n",
      "INFO:tensorflow:loss = 37.53332, step = 12401 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.483\n",
      "INFO:tensorflow:loss = 47.78398, step = 12501 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.743\n",
      "INFO:tensorflow:loss = 35.623535, step = 12601 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.023\n",
      "INFO:tensorflow:loss = 44.979527, step = 12701 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.6\n",
      "INFO:tensorflow:loss = 38.107105, step = 12801 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.542\n",
      "INFO:tensorflow:loss = 42.454716, step = 12901 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.63\n",
      "INFO:tensorflow:loss = 34.847633, step = 13001 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.758\n",
      "INFO:tensorflow:loss = 43.185745, step = 13101 (0.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.287\n",
      "INFO:tensorflow:loss = 39.16292, step = 13201 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.632\n",
      "INFO:tensorflow:loss = 37.575066, step = 13301 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.176\n",
      "INFO:tensorflow:loss = 44.245464, step = 13401 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.813\n",
      "INFO:tensorflow:loss = 41.060276, step = 13501 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.095\n",
      "INFO:tensorflow:loss = 36.837456, step = 13601 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.189\n",
      "INFO:tensorflow:loss = 39.351337, step = 13701 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.73\n",
      "INFO:tensorflow:loss = 40.761116, step = 13801 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.074\n",
      "INFO:tensorflow:loss = 47.564423, step = 13901 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.304\n",
      "INFO:tensorflow:loss = 40.203938, step = 14001 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.862\n",
      "INFO:tensorflow:loss = 51.750893, step = 14101 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.096\n",
      "INFO:tensorflow:loss = 34.34613, step = 14201 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.906\n",
      "INFO:tensorflow:loss = 30.511683, step = 14301 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.757\n",
      "INFO:tensorflow:loss = 41.977978, step = 14401 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.629\n",
      "INFO:tensorflow:loss = 35.03395, step = 14501 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.895\n",
      "INFO:tensorflow:loss = 56.165337, step = 14601 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.899\n",
      "INFO:tensorflow:loss = 42.55457, step = 14701 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.856\n",
      "INFO:tensorflow:loss = 39.64348, step = 14801 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.121\n",
      "INFO:tensorflow:loss = 43.164917, step = 14901 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.012\n",
      "INFO:tensorflow:loss = 36.708393, step = 15001 (0.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.38\n",
      "INFO:tensorflow:loss = 37.01996, step = 15101 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.222\n",
      "INFO:tensorflow:loss = 32.31325, step = 15201 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.73\n",
      "INFO:tensorflow:loss = 35.500374, step = 15301 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 54.39798, step = 15401 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.922\n",
      "INFO:tensorflow:loss = 38.30051, step = 15501 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.806\n",
      "INFO:tensorflow:loss = 41.912685, step = 15601 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.848\n",
      "INFO:tensorflow:loss = 37.323605, step = 15701 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.277\n",
      "INFO:tensorflow:loss = 36.962093, step = 15801 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.195\n",
      "INFO:tensorflow:loss = 46.116932, step = 15901 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.244\n",
      "INFO:tensorflow:loss = 46.39279, step = 16001 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.369\n",
      "INFO:tensorflow:loss = 37.96465, step = 16101 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.154\n",
      "INFO:tensorflow:loss = 48.979214, step = 16201 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.452\n",
      "INFO:tensorflow:loss = 26.889063, step = 16301 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.033\n",
      "INFO:tensorflow:loss = 37.65572, step = 16401 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.778\n",
      "INFO:tensorflow:loss = 41.368164, step = 16501 (0.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.591\n",
      "INFO:tensorflow:loss = 44.152145, step = 16601 (0.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.233\n",
      "INFO:tensorflow:loss = 29.915867, step = 16701 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.338\n",
      "INFO:tensorflow:loss = 35.653557, step = 16801 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.9\n",
      "INFO:tensorflow:loss = 50.799934, step = 16901 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.727\n",
      "INFO:tensorflow:loss = 44.40045, step = 17001 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.72\n",
      "INFO:tensorflow:loss = 57.025253, step = 17101 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.968\n",
      "INFO:tensorflow:loss = 39.103382, step = 17201 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.032\n",
      "INFO:tensorflow:loss = 40.084564, step = 17301 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.378\n",
      "INFO:tensorflow:loss = 38.295826, step = 17401 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.722\n",
      "INFO:tensorflow:loss = 41.53421, step = 17501 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.468\n",
      "INFO:tensorflow:loss = 48.27347, step = 17601 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.5\n",
      "INFO:tensorflow:loss = 43.315422, step = 17701 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.987\n",
      "INFO:tensorflow:loss = 51.816208, step = 17801 (0.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.238\n",
      "INFO:tensorflow:loss = 37.728092, step = 17901 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.762\n",
      "INFO:tensorflow:loss = 54.555687, step = 18001 (0.559 sec)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard import summary as summary_lib\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "dir='/Users/xinwang/ai/dataset/kaggle/DonorsChoose/'\n",
    "train_file=dir + 'train_1.csv'\n",
    "eval_file=dir + 'train_2.csv'\n",
    "model_dir = \"/Users/xinwang/Downloads/models_temp/\"\n",
    "label = LabelEncoder()\n",
    "\n",
    "CSV_COLUMNS = ['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
    "       'project_submitted_datetime', 'project_grade_category',\n",
    "       'project_subject_categories', 'project_subject_subcategories',\n",
    "       'project_title', 'project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
    "       'teacher_number_of_previously_posted_projects', 'project_is_approved']\n",
    "target = 'project_is_approved'\n",
    "\n",
    "summary_vocab_size=10000\n",
    "summary_sentence_size=50\n",
    "summary_embedding_size=20\n",
    "\n",
    "essay_vocab_size=30000\n",
    "essay_sentence_size=200\n",
    "essay_embedding_size=50\n",
    "\n",
    "teacher_id = tf.feature_column.categorical_column_with_hash_bucket('teacher_id', hash_bucket_size=1000)\n",
    "\n",
    "teacher_prefix = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"teacher_prefix\", [\n",
    "        \"Mrs.\",\"Ms.\",\"Mr.\",\"Teacher\",\"Dr.\"\n",
    "    ])\n",
    "teacher_prefix_bins = tf.feature_column.numeric_column('teacher_prefix_bins')\n",
    "\n",
    "school_state = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"school_state\",[\n",
    "        \"AK\",\"AL\",\"AR\",\"AZ\",\"CA\",\"CO\",\"CT\",\"DC\",\"DE\",\"FL\",\"GA\",\"HI\",\"IA\",\"ID\",\"IL\",\n",
    "        \"IN\",\"KS\",\"KY\",\"LA\",\"MA\",\"MD\",\"ME\",\"MI\",\"MN\",\"MO\",\"MS\",\"MT\",\"NC\",\"ND\",\"NE\",\n",
    "        \"NH\",\"NJ\",\"NM\",\"NV\",\"NY\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\n",
    "        \"TX\",\"UT\",\"VA\",\"VT\",\"WA\",\"WI\",\"WV\",\"WY\"\n",
    "    ])\n",
    "school_state_bins = tf.feature_column.numeric_column('school_state_bins')\n",
    "\n",
    "project_grade_category = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_grade_category\",[\"Grades 3-5\",\"Grades 6-8\",\"Grades 9-12\",\"Grades PreK-2\"])\n",
    "project_grade_category_bins = tf.feature_column.numeric_column('project_grade_category_bins')\n",
    "\n",
    "project_subject_categories = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_subject_categories\",[\n",
    "       \"Applied Learning\",\"Health & Sports\",\"History & Civics\",\"Literacy & Language\",\n",
    "        \"Math & Science\",\"Music & The Arts\",\"Special Needs\",\"Warmth\"])\n",
    "project_subject_categories_bins = tf.feature_column.numeric_column('project_subject_categories_bins')\n",
    "\n",
    "project_subject_subcategories = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_subject_subcategories\",[\n",
    "        \"Applied Learning\",\"Care & Hunger\",\"Health & Sports\",\"History & Civics\",\n",
    "        \"Literacy & Language\",\"Math & Science\",\"Music & The Arts\",\n",
    "        \"Warmth\",\"Applied Sciences\",\"Character Education\",\"Civics & Government\",\n",
    "        \"College & Career Prep\",\"Community Service\",\"ESL\",\"Early Development\",\n",
    "        \"Economics\",\"Environmental Science\",\"Extracurricular\",\"Financial Literacy\",\n",
    "        \"Foreign Languages\",\"Gym & Fitness\",\"Health & Life Science\",\"Health & Wellness\",\n",
    "        \"History & Geography\",\"Literacy\",\"Literature & Writing\",\"Mathematics\",\"Music\",\n",
    "        \"Nutrition Education\",\"Other\",\"Parent Involvement\",\"Performing Arts\",\n",
    "        \"Social Sciences\",\"Special Needs\",\"Team Sports\",\"Visual Arts\"])\n",
    "project_subject_subcategories_bins = tf.feature_column.numeric_column('project_subject_subcategories_bins')\n",
    "\n",
    "posted_projects = tf.feature_column.numeric_column('teacher_number_of_previously_posted_projects')\n",
    "\n",
    "summary_vec = tf.feature_column.categorical_column_with_identity('project_resource_summary_vec', summary_vocab_size)\n",
    "\n",
    "####################Text#########################\n",
    "\n",
    "basic_columns = [\n",
    "\n",
    "]\n",
    "\n",
    "crossed_columns = [\n",
    "    tf.feature_column.crossed_column(['teacher_prefix','school_state'],\n",
    "                                    hash_bucket_size=400),\n",
    "    tf.feature_column.crossed_column(['school_state','project_grade_category'],\n",
    "                                    hash_bucket_size=400),\n",
    "    tf.feature_column.crossed_column(['project_grade_category','project_subject_categories'],\n",
    "                                    hash_bucket_size=400),\n",
    "    tf.feature_column.crossed_column(['project_subject_categories','project_subject_subcategories'],\n",
    "                                   hash_bucket_size=400)\n",
    "]\n",
    "deep_columns = [\n",
    "    teacher_prefix_bins,\n",
    "    school_state_bins,\n",
    "    project_grade_category_bins,\n",
    "    project_subject_categories_bins,\n",
    "    project_subject_subcategories_bins,\n",
    "    posted_projects,\n",
    "        \n",
    "    tf.feature_column.indicator_column(teacher_id),\n",
    "    tf.feature_column.indicator_column(teacher_prefix),\n",
    "    tf.feature_column.indicator_column(school_state),\n",
    "    tf.feature_column.indicator_column(project_grade_category),\n",
    "    tf.feature_column.indicator_column(project_subject_categories),\n",
    "    tf.feature_column.indicator_column(project_subject_subcategories),\n",
    "    \n",
    "    tf.feature_column.embedding_column(summary_vec, dimension=10)\n",
    "]\n",
    "\n",
    "\n",
    "def text_2_vec(feature_name, data_set, vocab_size, sentence_size):\n",
    "    texts = data_set[feature_name].values\n",
    "    \n",
    "    tokenizer = Tokenizer(vocab_size)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequence_data = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    data = sequence.pad_sequences(sequence_data, \n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "    print(feature_name + \" text_2_vec data shape:\", data.shape)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def build_input_features_dict(input_df):\n",
    "    features = {}\n",
    "    features['teacher_id'] = input_df['teacher_id'].values\n",
    "    \n",
    "    features['teacher_prefix'] = input_df['teacher_prefix'].values\n",
    "    features['teacher_prefix_bins'] = input_df['teacher_prefix_bins'].values\n",
    "    \n",
    "    features['school_state'] = input_df['school_state'].values\n",
    "    features['school_state_bins'] = input_df['school_state_bins'].values\n",
    "    \n",
    "    features['project_grade_category'] = input_df['project_grade_category'].values\n",
    "    features['project_grade_category_bins'] = input_df['project_grade_category_bins'].values\n",
    "\n",
    "    features['project_subject_categories'] = input_df['project_subject_categories'].values\n",
    "    features['project_subject_categories_bins'] = input_df['project_subject_categories_bins'].values\n",
    "\n",
    "    features['project_subject_subcategories'] = input_df['project_subject_subcategories'].values\n",
    "    features['project_subject_subcategories_bins'] = input_df['project_subject_subcategories_bins'].values\n",
    "    \n",
    "    features['teacher_number_of_previously_posted_projects'] = input_df['teacher_number_of_previously_posted_projects'].values\n",
    "\n",
    "    ############################  Text columns  ############################\n",
    "    features['project_resource_summary_vec'] = text_2_vec('project_resource_summary',\n",
    "                                                          input_df, \n",
    "                                                          summary_vocab_size,\n",
    "                                                          summary_sentence_size)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def input_fn(file, num_epochs, shuffle):\n",
    "    input_df = pd.read_csv(\n",
    "        tf.gfile.Open(file),names=CSV_COLUMNS,\n",
    "        skipinitialspace=True,engine=\"python\",skiprows=1)\n",
    "    \n",
    "    input_df.dropna(subset=[\"teacher_prefix\"], inplace=True)  \n",
    "    input_df['teacher_prefix_bins'] = label.fit_transform(input_df['teacher_prefix'])\n",
    "\n",
    "    input_df['school_state_bins'] = label.fit_transform(input_df['school_state'])\n",
    "    input_df['project_grade_category_bins'] = label.fit_transform(input_df['project_grade_category'])\n",
    "    input_df['project_subject_categories_bins'] = label.fit_transform(input_df['project_subject_categories'])\n",
    "    input_df['project_subject_subcategories_bins'] = label.fit_transform(input_df['project_subject_subcategories'])\n",
    "    \n",
    "    features = build_input_features_dict(input_df)\n",
    "    labels = input_df[target].values\n",
    "    \n",
    "    return tf.estimator.inputs.numpy_input_fn(features,\n",
    "                                              labels,\n",
    "                                              batch_size=100,\n",
    "                                              num_epochs=num_epochs,\n",
    "                                              shuffle=shuffle,\n",
    "                                              num_threads=5)\n",
    "\n",
    "def buildClassifier():\n",
    "    m = tf.estimator.DNNLinearCombinedClassifier(\n",
    "        linear_feature_columns = basic_columns + crossed_columns,\n",
    "        dnn_feature_columns = deep_columns,\n",
    "        dnn_hidden_units=[100, 50])\n",
    "    return m\n",
    "    \n",
    "def train_and_evaluate():\n",
    "    classifier = buildClassifier()\n",
    "\n",
    "    classifier.train(input_fn=input_fn(train_file, num_epochs=None, shuffle=True), \n",
    "                     steps = 20000)\n",
    "    results = classifier.evaluate(input_fn=input_fn(eval_file, num_epochs=1, shuffle=False),\n",
    "                                      steps=None)\n",
    "    \n",
    "    print('-'*100)\n",
    "    for key in sorted(results):\n",
    "        print(\"%s: %s\" % (key, results[key]))\n",
    "        \n",
    "        \n",
    "    \n",
    "train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
