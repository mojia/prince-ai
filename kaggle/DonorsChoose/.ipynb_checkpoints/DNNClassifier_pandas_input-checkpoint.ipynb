{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp1_l_3foa\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp1_l_3foa', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x122c682b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "project_resource_summary text_2_vec data shape: (59997, 50)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp1_l_3foa/model.ckpt.\n",
      "INFO:tensorflow:loss = 127.78249, step = 1\n",
      "INFO:tensorflow:global_step/sec: 68.7294\n",
      "INFO:tensorflow:loss = 38.74341, step = 101 (1.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.3288\n",
      "INFO:tensorflow:loss = 40.508076, step = 201 (1.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.3011\n",
      "INFO:tensorflow:loss = 40.904724, step = 301 (1.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.847\n",
      "INFO:tensorflow:loss = 39.109123, step = 401 (1.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.9317\n",
      "INFO:tensorflow:loss = 30.891575, step = 501 (1.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.1289\n",
      "INFO:tensorflow:loss = 47.955544, step = 601 (1.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.352\n",
      "INFO:tensorflow:loss = 35.85991, step = 701 (1.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.5617\n",
      "INFO:tensorflow:loss = 47.443565, step = 801 (1.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.6195\n",
      "INFO:tensorflow:loss = 42.331146, step = 901 (1.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.5607\n",
      "INFO:tensorflow:loss = 42.751987, step = 1001 (1.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.0737\n",
      "INFO:tensorflow:loss = 43.45526, step = 1101 (1.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.992\n",
      "INFO:tensorflow:loss = 32.989887, step = 1201 (1.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.6124\n",
      "INFO:tensorflow:loss = 40.69268, step = 1301 (1.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.2046\n",
      "INFO:tensorflow:loss = 42.885803, step = 1401 (1.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.1693\n",
      "INFO:tensorflow:loss = 58.157257, step = 1501 (1.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.8369\n",
      "INFO:tensorflow:loss = 44.12921, step = 1601 (1.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.9568\n",
      "INFO:tensorflow:loss = 43.44634, step = 1701 (1.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.1287\n",
      "INFO:tensorflow:loss = 47.415424, step = 1801 (1.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.8473\n",
      "INFO:tensorflow:loss = 35.024742, step = 1901 (1.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.8804\n",
      "INFO:tensorflow:loss = 46.639053, step = 2001 (1.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.6643\n",
      "INFO:tensorflow:loss = 36.26956, step = 2101 (1.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.6703\n",
      "INFO:tensorflow:loss = 44.95336, step = 2201 (1.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.3567\n",
      "INFO:tensorflow:loss = 39.153027, step = 2301 (1.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.1663\n",
      "INFO:tensorflow:loss = 40.003517, step = 2401 (1.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.1899\n",
      "INFO:tensorflow:loss = 48.45942, step = 2501 (1.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.409\n",
      "INFO:tensorflow:loss = 35.605778, step = 2601 (1.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.9543\n",
      "INFO:tensorflow:loss = 48.498466, step = 2701 (1.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.4819\n",
      "INFO:tensorflow:loss = 44.25457, step = 2801 (1.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.111\n",
      "INFO:tensorflow:loss = 50.247444, step = 2901 (1.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.9008\n",
      "INFO:tensorflow:loss = 34.85407, step = 3001 (1.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.6728\n",
      "INFO:tensorflow:loss = 44.091873, step = 3101 (1.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.9493\n",
      "INFO:tensorflow:loss = 45.608475, step = 3201 (1.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.3855\n",
      "INFO:tensorflow:loss = 35.897373, step = 3301 (1.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.452\n",
      "INFO:tensorflow:loss = 41.907578, step = 3401 (1.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.1837\n",
      "INFO:tensorflow:loss = 41.78484, step = 3501 (1.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.9949\n",
      "INFO:tensorflow:loss = 40.74678, step = 3601 (1.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.9103\n",
      "INFO:tensorflow:loss = 27.526478, step = 3701 (1.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.0656\n",
      "INFO:tensorflow:loss = 40.113567, step = 3801 (1.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.9515\n",
      "INFO:tensorflow:loss = 41.527405, step = 3901 (1.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.7454\n",
      "INFO:tensorflow:loss = 51.79172, step = 4001 (1.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.5301\n",
      "INFO:tensorflow:loss = 43.467422, step = 4101 (1.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.6569\n",
      "INFO:tensorflow:loss = 38.87083, step = 4201 (1.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.8378\n",
      "INFO:tensorflow:loss = 30.389517, step = 4301 (1.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.5023\n",
      "INFO:tensorflow:loss = 38.062862, step = 4401 (1.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.0758\n",
      "INFO:tensorflow:loss = 50.595863, step = 4501 (1.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.3923\n",
      "INFO:tensorflow:loss = 37.500465, step = 4601 (1.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.3685\n",
      "INFO:tensorflow:loss = 33.75389, step = 4701 (1.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.2825\n",
      "INFO:tensorflow:loss = 38.455063, step = 4801 (1.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.139\n",
      "INFO:tensorflow:loss = 44.681427, step = 4901 (1.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.8215\n",
      "INFO:tensorflow:loss = 44.965984, step = 5001 (1.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5466\n",
      "INFO:tensorflow:loss = 50.49913, step = 5101 (1.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.0664\n",
      "INFO:tensorflow:loss = 45.2037, step = 5201 (1.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.1703\n",
      "INFO:tensorflow:loss = 38.653473, step = 5301 (1.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.123\n",
      "INFO:tensorflow:loss = 43.3509, step = 5401 (1.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.8437\n",
      "INFO:tensorflow:loss = 33.306305, step = 5501 (1.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.7696\n",
      "INFO:tensorflow:loss = 43.14484, step = 5601 (1.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.654\n",
      "INFO:tensorflow:loss = 46.390316, step = 5701 (1.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.0421\n",
      "INFO:tensorflow:loss = 42.637848, step = 5801 (1.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.5054\n",
      "INFO:tensorflow:loss = 48.096565, step = 5901 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.2218\n",
      "INFO:tensorflow:loss = 42.11045, step = 6001 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1587\n",
      "INFO:tensorflow:loss = 30.621311, step = 6101 (1.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.3654\n",
      "INFO:tensorflow:loss = 43.60103, step = 6201 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.7401\n",
      "INFO:tensorflow:loss = 39.603897, step = 6301 (1.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.6496\n",
      "INFO:tensorflow:loss = 44.995964, step = 6401 (1.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.6777\n",
      "INFO:tensorflow:loss = 39.101665, step = 6501 (1.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.1453\n",
      "INFO:tensorflow:loss = 53.33532, step = 6601 (1.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.1926\n",
      "INFO:tensorflow:loss = 30.700369, step = 6701 (1.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.9515\n",
      "INFO:tensorflow:loss = 47.64441, step = 6801 (1.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.8927\n",
      "INFO:tensorflow:loss = 50.378117, step = 6901 (1.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.837\n",
      "INFO:tensorflow:loss = 44.385296, step = 7001 (1.066 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 93.3566\n",
      "INFO:tensorflow:loss = 46.06017, step = 7101 (1.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.9416\n",
      "INFO:tensorflow:loss = 28.571085, step = 7201 (1.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.9156\n",
      "INFO:tensorflow:loss = 36.333584, step = 7301 (1.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.2674\n",
      "INFO:tensorflow:loss = 39.32615, step = 7401 (1.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.2137\n",
      "INFO:tensorflow:loss = 48.401115, step = 7501 (1.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0335\n",
      "INFO:tensorflow:loss = 45.5672, step = 7601 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.8093\n",
      "INFO:tensorflow:loss = 37.94393, step = 7701 (1.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.3341\n",
      "INFO:tensorflow:loss = 44.931038, step = 7801 (1.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.3432\n",
      "INFO:tensorflow:loss = 48.488194, step = 7901 (1.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.8594\n",
      "INFO:tensorflow:loss = 42.0667, step = 8001 (1.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.091\n",
      "INFO:tensorflow:loss = 51.445686, step = 8101 (1.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9634\n",
      "INFO:tensorflow:loss = 41.0289, step = 8201 (1.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7973\n",
      "INFO:tensorflow:loss = 32.821987, step = 8301 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.7558\n",
      "INFO:tensorflow:loss = 60.39044, step = 8401 (1.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.3872\n",
      "INFO:tensorflow:loss = 39.666702, step = 8501 (1.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9712\n",
      "INFO:tensorflow:loss = 35.47256, step = 8601 (1.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.8717\n",
      "INFO:tensorflow:loss = 49.412354, step = 8701 (1.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.397\n",
      "INFO:tensorflow:loss = 45.874016, step = 8801 (1.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.4543\n",
      "INFO:tensorflow:loss = 30.044249, step = 8901 (1.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.3539\n",
      "INFO:tensorflow:loss = 41.032383, step = 9001 (1.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.4974\n",
      "INFO:tensorflow:loss = 39.36178, step = 9101 (1.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.3296\n",
      "INFO:tensorflow:loss = 40.293713, step = 9201 (1.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.4976\n",
      "INFO:tensorflow:loss = 37.6021, step = 9301 (1.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.5458\n",
      "INFO:tensorflow:loss = 38.67885, step = 9401 (1.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.7097\n",
      "INFO:tensorflow:loss = 46.407177, step = 9501 (1.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.6996\n",
      "INFO:tensorflow:loss = 51.4889, step = 9601 (1.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.9003\n",
      "INFO:tensorflow:loss = 41.55628, step = 9701 (1.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.9235\n",
      "INFO:tensorflow:loss = 46.49339, step = 9801 (1.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.9261\n",
      "INFO:tensorflow:loss = 47.452915, step = 9901 (1.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.794\n",
      "INFO:tensorflow:loss = 42.44477, step = 10001 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.1397\n",
      "INFO:tensorflow:loss = 34.656063, step = 10101 (1.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.3857\n",
      "INFO:tensorflow:loss = 34.083157, step = 10201 (1.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.6408\n",
      "INFO:tensorflow:loss = 33.19978, step = 10301 (1.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.5273\n",
      "INFO:tensorflow:loss = 42.358273, step = 10401 (1.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.2553\n",
      "INFO:tensorflow:loss = 42.879967, step = 10501 (1.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.5795\n",
      "INFO:tensorflow:loss = 34.0382, step = 10601 (1.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.8224\n",
      "INFO:tensorflow:loss = 40.73513, step = 10701 (1.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.6329\n",
      "INFO:tensorflow:loss = 33.84523, step = 10801 (1.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.3312\n",
      "INFO:tensorflow:loss = 41.921875, step = 10901 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7312\n",
      "INFO:tensorflow:loss = 41.61187, step = 11001 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.3668\n",
      "INFO:tensorflow:loss = 49.132748, step = 11101 (1.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.4121\n",
      "INFO:tensorflow:loss = 39.66074, step = 11201 (1.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.2125\n",
      "INFO:tensorflow:loss = 38.967335, step = 11301 (1.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.9359\n",
      "INFO:tensorflow:loss = 45.79939, step = 11401 (1.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.8002\n",
      "INFO:tensorflow:loss = 43.674618, step = 11501 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0067\n",
      "INFO:tensorflow:loss = 41.027657, step = 11601 (1.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.5363\n",
      "INFO:tensorflow:loss = 36.93075, step = 11701 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.5616\n",
      "INFO:tensorflow:loss = 50.80779, step = 11801 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0275\n",
      "INFO:tensorflow:loss = 48.125664, step = 11901 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.5643\n",
      "INFO:tensorflow:loss = 36.251724, step = 12001 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.3238\n",
      "INFO:tensorflow:loss = 44.995155, step = 12101 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.903\n",
      "INFO:tensorflow:loss = 39.121357, step = 12201 (1.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.1368\n",
      "INFO:tensorflow:loss = 42.13952, step = 12301 (1.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.093\n",
      "INFO:tensorflow:loss = 35.47667, step = 12401 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.6248\n",
      "INFO:tensorflow:loss = 46.08931, step = 12501 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.3309\n",
      "INFO:tensorflow:loss = 37.018093, step = 12601 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.4368\n",
      "INFO:tensorflow:loss = 35.272564, step = 12701 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3933\n",
      "INFO:tensorflow:loss = 36.227745, step = 12801 (1.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3074\n",
      "INFO:tensorflow:loss = 52.229706, step = 12901 (1.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.5005\n",
      "INFO:tensorflow:loss = 33.78939, step = 13001 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.4138\n",
      "INFO:tensorflow:loss = 37.59018, step = 13101 (1.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9465\n",
      "INFO:tensorflow:loss = 33.572117, step = 13201 (1.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.4388\n",
      "INFO:tensorflow:loss = 48.02593, step = 13301 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7839\n",
      "INFO:tensorflow:loss = 40.323112, step = 13401 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.7772\n",
      "INFO:tensorflow:loss = 37.2754, step = 13501 (1.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.2076\n",
      "INFO:tensorflow:loss = 35.06219, step = 13601 (1.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.9245\n",
      "INFO:tensorflow:loss = 40.31561, step = 13701 (1.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.4131\n",
      "INFO:tensorflow:loss = 37.28037, step = 13801 (1.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.8701\n",
      "INFO:tensorflow:loss = 34.481956, step = 13901 (1.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.3956\n",
      "INFO:tensorflow:loss = 43.159317, step = 14001 (1.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.0973\n",
      "INFO:tensorflow:loss = 42.330387, step = 14101 (1.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.6992\n",
      "INFO:tensorflow:loss = 41.510506, step = 14201 (1.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.3822\n",
      "INFO:tensorflow:loss = 33.097626, step = 14301 (1.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.0586\n",
      "INFO:tensorflow:loss = 39.37339, step = 14401 (1.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.6899\n",
      "INFO:tensorflow:loss = 38.7391, step = 14501 (1.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.555\n",
      "INFO:tensorflow:loss = 44.739822, step = 14601 (1.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.8397\n",
      "INFO:tensorflow:loss = 35.683987, step = 14701 (1.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1084\n",
      "INFO:tensorflow:loss = 55.36859, step = 14801 (1.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7377\n",
      "INFO:tensorflow:loss = 45.12249, step = 14901 (1.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.0883\n",
      "INFO:tensorflow:loss = 41.352943, step = 15001 (1.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.578\n",
      "INFO:tensorflow:loss = 36.63795, step = 15101 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.7355\n",
      "INFO:tensorflow:loss = 45.209534, step = 15201 (1.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.0459\n",
      "INFO:tensorflow:loss = 35.383358, step = 15301 (1.099 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 89.0663\n",
      "INFO:tensorflow:loss = 38.74178, step = 15401 (1.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.981\n",
      "INFO:tensorflow:loss = 52.476234, step = 15501 (1.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.4954\n",
      "INFO:tensorflow:loss = 42.737293, step = 15601 (1.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2905\n",
      "INFO:tensorflow:loss = 44.797543, step = 15701 (1.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.711\n",
      "INFO:tensorflow:loss = 43.4347, step = 15801 (1.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.9665\n",
      "INFO:tensorflow:loss = 41.97924, step = 15901 (1.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.4363\n",
      "INFO:tensorflow:loss = 39.788208, step = 16001 (1.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.4881\n",
      "INFO:tensorflow:loss = 46.326164, step = 16101 (1.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.7951\n",
      "INFO:tensorflow:loss = 28.670942, step = 16201 (1.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.4744\n",
      "INFO:tensorflow:loss = 35.67997, step = 16301 (1.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.698\n",
      "INFO:tensorflow:loss = 43.968376, step = 16401 (1.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.777\n",
      "INFO:tensorflow:loss = 43.792038, step = 16501 (1.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.89\n",
      "INFO:tensorflow:loss = 41.507877, step = 16601 (1.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.8088\n",
      "INFO:tensorflow:loss = 49.980316, step = 16701 (1.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.3573\n",
      "INFO:tensorflow:loss = 41.31943, step = 16801 (1.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.5247\n",
      "INFO:tensorflow:loss = 35.52566, step = 16901 (1.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.2949\n",
      "INFO:tensorflow:loss = 38.195374, step = 17001 (1.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.2692\n",
      "INFO:tensorflow:loss = 44.34605, step = 17101 (1.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.8292\n",
      "INFO:tensorflow:loss = 36.487194, step = 17201 (1.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.965\n",
      "INFO:tensorflow:loss = 35.095665, step = 17301 (1.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.1752\n",
      "INFO:tensorflow:loss = 27.78132, step = 17401 (1.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.0623\n",
      "INFO:tensorflow:loss = 38.468555, step = 17501 (1.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.2481\n",
      "INFO:tensorflow:loss = 38.421608, step = 17601 (1.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.72\n",
      "INFO:tensorflow:loss = 47.376465, step = 17701 (1.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.3337\n",
      "INFO:tensorflow:loss = 37.940502, step = 17801 (1.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7637\n",
      "INFO:tensorflow:loss = 49.251198, step = 17901 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.2383\n",
      "INFO:tensorflow:loss = 37.99923, step = 18001 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.3446\n",
      "INFO:tensorflow:loss = 39.073174, step = 18101 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.8481\n",
      "INFO:tensorflow:loss = 38.47931, step = 18201 (1.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.8612\n",
      "INFO:tensorflow:loss = 29.322239, step = 18301 (1.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.3515\n",
      "INFO:tensorflow:loss = 33.06401, step = 18401 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.1903\n",
      "INFO:tensorflow:loss = 49.742123, step = 18501 (1.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.2479\n",
      "INFO:tensorflow:loss = 43.818863, step = 18601 (1.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.5241\n",
      "INFO:tensorflow:loss = 34.249275, step = 18701 (1.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1979\n",
      "INFO:tensorflow:loss = 35.83201, step = 18801 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.019\n",
      "INFO:tensorflow:loss = 40.80573, step = 18901 (1.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.9991\n",
      "INFO:tensorflow:loss = 27.67289, step = 19001 (1.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.541\n",
      "INFO:tensorflow:loss = 34.029312, step = 19101 (1.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.0782\n",
      "INFO:tensorflow:loss = 41.859665, step = 19201 (1.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.528\n",
      "INFO:tensorflow:loss = 41.8733, step = 19301 (1.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.5746\n",
      "INFO:tensorflow:loss = 37.635006, step = 19401 (1.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.6425\n",
      "INFO:tensorflow:loss = 35.224323, step = 19501 (1.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.8276\n",
      "INFO:tensorflow:loss = 37.61516, step = 19601 (1.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.4472\n",
      "INFO:tensorflow:loss = 45.124588, step = 19701 (1.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.5973\n",
      "INFO:tensorflow:loss = 24.065825, step = 19801 (1.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.3867\n",
      "INFO:tensorflow:loss = 32.098526, step = 19901 (1.094 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp1_l_3foa/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 41.637547.\n",
      "project_resource_summary text_2_vec data shape: (59997, 50)\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=False and num_threads > 1. This will create multiple threads, all reading the array/dataframe in order. If you want examples read in order, use one thread; if you want multiple threads, enable shuffling.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-05-09:11:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp1_l_3foa/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-05-09:11:37\n",
      "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.84685904, accuracy_baseline = 0.84685904, auc = 0.6266319, auc_precision_recall = 0.8973431, average_loss = 0.41515437, global_step = 20000, label/mean = 0.84685904, loss = 41.513363, precision = 0.84685904, prediction/mean = 0.84779465, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmp1_l_3foa/model.ckpt-20000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "accuracy: 0.84685904\n",
      "accuracy_baseline: 0.84685904\n",
      "auc: 0.6266319\n",
      "auc_precision_recall: 0.8973431\n",
      "average_loss: 0.41515437\n",
      "global_step: 20000\n",
      "label/mean: 0.84685904\n",
      "loss: 41.513363\n",
      "precision: 0.84685904\n",
      "prediction/mean: 0.84779465\n",
      "recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard import summary as summary_lib\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "dir='/Users/xinwang/ai/dataset/kaggle/DonorsChoose/'\n",
    "train_file=dir + 'train_1.csv'\n",
    "eval_file=dir + 'train_2.csv'\n",
    "resource_file = dir + 'resources.csv'\n",
    "model_dir = \"/Users/xinwang/Downloads/models_temp/\"\n",
    "label = LabelEncoder()\n",
    "\n",
    "CSV_COLUMNS = ['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
    "       'project_submitted_datetime', 'project_grade_category',\n",
    "       'project_subject_categories', 'project_subject_subcategories',\n",
    "       'project_title', 'project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
    "       'teacher_number_of_previously_posted_projects', 'project_is_approved']\n",
    "RESOURCE_COLUMNS = ['id', 'description', 'quantity', 'price']\n",
    "target = 'project_is_approved'\n",
    "\n",
    "summary_vocab_size=10000\n",
    "summary_sentence_size=50\n",
    "summary_embedding_size=30\n",
    "\n",
    "essay_vocab_size=30000\n",
    "essay_sentence_size=200\n",
    "essay_embedding_size=50\n",
    "pad_id=0\n",
    "\n",
    "teacher_id = tf.feature_column.categorical_column_with_hash_bucket('teacher_id', hash_bucket_size=1000)\n",
    "\n",
    "project_title = tf.feature_column.categorical_column_with_hash_bucket('project_title', hash_bucket_size=5000)\n",
    "\n",
    "teacher_prefix = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"teacher_prefix\", [\n",
    "        \"Mrs.\",\"Ms.\",\"Mr.\",\"Teacher\",\"Dr.\"\n",
    "    ])\n",
    "teacher_prefix_bins = tf.feature_column.numeric_column('teacher_prefix_bins')\n",
    "\n",
    "school_state = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"school_state\",[\n",
    "        \"AK\",\"AL\",\"AR\",\"AZ\",\"CA\",\"CO\",\"CT\",\"DC\",\"DE\",\"FL\",\"GA\",\"HI\",\"IA\",\"ID\",\"IL\",\n",
    "        \"IN\",\"KS\",\"KY\",\"LA\",\"MA\",\"MD\",\"ME\",\"MI\",\"MN\",\"MO\",\"MS\",\"MT\",\"NC\",\"ND\",\"NE\",\n",
    "        \"NH\",\"NJ\",\"NM\",\"NV\",\"NY\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\n",
    "        \"TX\",\"UT\",\"VA\",\"VT\",\"WA\",\"WI\",\"WV\",\"WY\"\n",
    "    ])\n",
    "school_state_bins = tf.feature_column.numeric_column('school_state_bins')\n",
    "\n",
    "project_grade_category = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_grade_category\",[\"Grades 3-5\",\"Grades 6-8\",\"Grades 9-12\",\"Grades PreK-2\"])\n",
    "project_grade_category_bins = tf.feature_column.numeric_column('project_grade_category_bins')\n",
    "\n",
    "project_subject_categories = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_subject_categories\",[\n",
    "       \"Applied Learning\",\"Health & Sports\",\"History & Civics\",\"Literacy & Language\",\n",
    "        \"Math & Science\",\"Music & The Arts\",\"Special Needs\",\"Warmth\"])\n",
    "project_subject_categories_bins = tf.feature_column.numeric_column('project_subject_categories_bins')\n",
    "\n",
    "project_subject_subcategories = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"project_subject_subcategories\",[\n",
    "        \"Applied Learning\",\"Care & Hunger\",\"Health & Sports\",\"History & Civics\",\n",
    "        \"Literacy & Language\",\"Math & Science\",\"Music & The Arts\",\n",
    "        \"Warmth\",\"Applied Sciences\",\"Character Education\",\"Civics & Government\",\n",
    "        \"College & Career Prep\",\"Community Service\",\"ESL\",\"Early Development\",\n",
    "        \"Economics\",\"Environmental Science\",\"Extracurricular\",\"Financial Literacy\",\n",
    "        \"Foreign Languages\",\"Gym & Fitness\",\"Health & Life Science\",\"Health & Wellness\",\n",
    "        \"History & Geography\",\"Literacy\",\"Literature & Writing\",\"Mathematics\",\"Music\",\n",
    "        \"Nutrition Education\",\"Other\",\"Parent Involvement\",\"Performing Arts\",\n",
    "        \"Social Sciences\",\"Special Needs\",\"Team Sports\",\"Visual Arts\"])\n",
    "project_subject_subcategories_bins = tf.feature_column.numeric_column('project_subject_subcategories_bins')\n",
    "\n",
    "posted_projects = tf.feature_column.numeric_column('teacher_number_of_previously_posted_projects')\n",
    "posted_projects_bins = tf.feature_column.numeric_column('posted_projects_bins')\n",
    "\n",
    "quantity = tf.feature_column.numeric_column('quantity')\n",
    "price = tf.feature_column.numeric_column('price')\n",
    "\n",
    "\n",
    "#################### Text columns #########################\n",
    "summary_vec = tf.feature_column.categorical_column_with_identity('project_resource_summary_vec', summary_vocab_size)\n",
    "\n",
    "\n",
    "basic_columns = [\n",
    "\n",
    "]\n",
    "\n",
    "crossed_columns = [\n",
    "    tf.feature_column.crossed_column(['teacher_prefix','school_state'],\n",
    "                                    hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['school_state','project_grade_category'],\n",
    "                                    hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['project_grade_category','project_subject_categories'],\n",
    "                                    hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['project_subject_categories','project_subject_subcategories'],\n",
    "                                   hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(['project_subject_categories','posted_projects_bins'],\n",
    "                                   hash_bucket_size=1000)\n",
    "]\n",
    "deep_columns = [\n",
    "    teacher_prefix_bins,\n",
    "    school_state_bins,\n",
    "    project_grade_category_bins,\n",
    "    project_subject_categories_bins,\n",
    "    project_subject_subcategories_bins,\n",
    "    posted_projects,\n",
    "    quantity,\n",
    "    price,\n",
    "        \n",
    "    tf.feature_column.indicator_column(teacher_id),\n",
    "    tf.feature_column.indicator_column(project_title),\n",
    "    tf.feature_column.indicator_column(teacher_prefix),\n",
    "    tf.feature_column.indicator_column(school_state),\n",
    "    tf.feature_column.indicator_column(project_grade_category),\n",
    "    tf.feature_column.indicator_column(project_subject_categories),\n",
    "    tf.feature_column.indicator_column(project_subject_subcategories),\n",
    "    \n",
    "    tf.feature_column.embedding_column(summary_vec, dimension=10)\n",
    "]\n",
    "\n",
    "\n",
    "def text_2_vec(feature_name, data_set, vocab_size, sentence_size):\n",
    "    texts = data_set[feature_name].values\n",
    "    \n",
    "    tokenizer = Tokenizer(vocab_size)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequence_data = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    data = sequence.pad_sequences(sequence_data, \n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "    print(feature_name + \" text_2_vec data shape:\", data.shape)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def build_input_features_dict(input_df):\n",
    "    features = {}\n",
    "    features['teacher_id'] = input_df['teacher_id'].values\n",
    "    \n",
    "    features['project_title'] = input_df['project_title'].values\n",
    "    \n",
    "    features['teacher_prefix'] = input_df['teacher_prefix'].values\n",
    "    features['teacher_prefix_bins'] = input_df['teacher_prefix_bins'].values\n",
    "    \n",
    "    features['school_state'] = input_df['school_state'].values\n",
    "    features['school_state_bins'] = input_df['school_state_bins'].values\n",
    "    \n",
    "    features['project_grade_category'] = input_df['project_grade_category'].values\n",
    "    features['project_grade_category_bins'] = input_df['project_grade_category_bins'].values\n",
    "\n",
    "    features['project_subject_categories'] = input_df['project_subject_categories'].values\n",
    "    features['project_subject_categories_bins'] = input_df['project_subject_categories_bins'].values\n",
    "\n",
    "    features['project_subject_subcategories'] = input_df['project_subject_subcategories'].values\n",
    "    features['project_subject_subcategories_bins'] = input_df['project_subject_subcategories_bins'].values\n",
    "    \n",
    "    features['teacher_number_of_previously_posted_projects'] = input_df['teacher_number_of_previously_posted_projects'].values\n",
    "    features['posted_projects_bins'] = input_df['posted_projects_bins'].values\n",
    "    \n",
    "    features['quantity'] = input_df['quantity'].values\n",
    "    features['price'] = input_df['price'].values\n",
    "    \n",
    "    ############################  Text columns  ############################\n",
    "    features['project_resource_summary_vec'] = text_2_vec('project_resource_summary',\n",
    "                                                          input_df, \n",
    "                                                          summary_vocab_size,\n",
    "                                                          summary_sentence_size)\n",
    "    ############################  Text columns  ############################\n",
    "    \n",
    "    return features\n",
    "\n",
    "def input_fn(file, num_epochs, shuffle):\n",
    "    input_df = pd.read_csv(\n",
    "        tf.gfile.Open(file),names=CSV_COLUMNS,\n",
    "        skipinitialspace=True,engine=\"python\",skiprows=1)\n",
    "    resource_df = pd.read_csv(\n",
    "        tf.gfile.Open(resource_file),names=RESOURCE_COLUMNS,\n",
    "        skipinitialspace=True,engine=\"python\",skiprows=1)\n",
    "    \n",
    "    \n",
    "    input_df.dropna(subset=[\"teacher_prefix\"], inplace=True)\n",
    "    input_df['teacher_prefix_bins'] = label.fit_transform(input_df['teacher_prefix'])\n",
    "\n",
    "    input_df['school_state_bins'] = label.fit_transform(input_df['school_state'])\n",
    "    input_df['project_grade_category_bins'] = label.fit_transform(input_df['project_grade_category'])\n",
    "    input_df['project_subject_categories_bins'] = label.fit_transform(input_df['project_subject_categories'])\n",
    "    input_df['project_subject_subcategories_bins'] = label.fit_transform(input_df['project_subject_subcategories'])\n",
    "    \n",
    "    input_df['posted_projects_periods'] = pd.cut(input_df['teacher_number_of_previously_posted_projects'], \n",
    "                                                 [-1,7,50,1000])\n",
    "    input_df['posted_projects_bins'] = label.fit_transform(input_df['posted_projects_periods'])\n",
    "    \n",
    "    total_quantity_df = resource_df[['id','quantity']].groupby('id', as_index=False).sum()\n",
    "    total_price_df = resource_df[['id','price']].groupby('id', as_index=False).sum()\n",
    "\n",
    "    input_df = pd.merge(input_df, total_quantity_df, how='inner', on='id')\n",
    "    input_df = pd.merge(input_df, total_price_df, how='inner', on='id')\n",
    "\n",
    "     \n",
    "    features = build_input_features_dict(input_df)\n",
    "    labels = input_df[target].values\n",
    "    \n",
    "    return tf.estimator.inputs.numpy_input_fn(features,\n",
    "                                              labels,\n",
    "                                              batch_size=100,\n",
    "                                              num_epochs=num_epochs,\n",
    "                                              shuffle=shuffle,\n",
    "                                              num_threads=5)\n",
    "\n",
    "def buildClassifier():\n",
    "    m = tf.estimator.DNNLinearCombinedClassifier(\n",
    "        linear_feature_columns = basic_columns + crossed_columns,\n",
    "        dnn_feature_columns = deep_columns,\n",
    "        dnn_hidden_units=[100])\n",
    "    return m\n",
    "    \n",
    "def train_and_evaluate():\n",
    "    classifier = buildClassifier()\n",
    "\n",
    "    classifier.train(input_fn=input_fn(train_file, num_epochs=None, shuffle=True), \n",
    "                     steps = 20000)\n",
    "    results = classifier.evaluate(input_fn=input_fn(eval_file, num_epochs=1, shuffle=False),\n",
    "                                      steps=None)\n",
    "    \n",
    "    print('-'*100)\n",
    "    for key in sorted(results):\n",
    "        print(\"%s: %s\" % (key, results[key]))\n",
    "        \n",
    "        \n",
    "    \n",
    "train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
