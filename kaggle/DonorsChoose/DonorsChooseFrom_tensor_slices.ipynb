{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinwang/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>484aaf11257089a66cfedc9461c6bd0a</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:59</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Super Sight Word Centers</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>I currently have a differentiated sight word c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need 6 Ipod Nano's to create and d...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p039565</td>\n",
       "      <td>df72a3ba8089423fa8a94be88060f6ed</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:28</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Music &amp; The Arts, Health &amp; Sports</td>\n",
       "      <td>Performing Arts, Team Sports</td>\n",
       "      <td>Keep Calm and Dance On</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>We strive to provide our diverse population of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need matching shirts to wear for d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p233823</td>\n",
       "      <td>a9b876a9252e08a55e3d894150f75ba3</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>UT</td>\n",
       "      <td>2017-01-01 22:57:44</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Math &amp; Science, Literacy &amp; Language</td>\n",
       "      <td>Applied Sciences, Literature &amp; Writing</td>\n",
       "      <td>Lets 3Doodle to Learn</td>\n",
       "      <td>Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...</td>\n",
       "      <td>We are looking to add some 3Doodler to our cla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need the 3doodler. We are an SEM s...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p185307</td>\n",
       "      <td>525fdbb6ec7f538a48beebaa0a51b24f</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-08-12 15:42:11</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>\\\"Kid Inspired\\\" Equipment to Increase Activit...</td>\n",
       "      <td>My students are the greatest students but are ...</td>\n",
       "      <td>The student's project which is totally \\\"kid-i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need balls and other activity equi...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p013780</td>\n",
       "      <td>a63b5547a7239eae4c1872670848e61a</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-08-06 09:09:11</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>We need clean water for our culinary arts class!</td>\n",
       "      <td>My students are athletes and students who are ...</td>\n",
       "      <td>For some reason in our kitchen the water comes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need a water filtration system for...</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        teacher_id teacher_prefix school_state  \\\n",
       "0  p036502  484aaf11257089a66cfedc9461c6bd0a            Ms.           NV   \n",
       "1  p039565  df72a3ba8089423fa8a94be88060f6ed           Mrs.           GA   \n",
       "2  p233823  a9b876a9252e08a55e3d894150f75ba3            Ms.           UT   \n",
       "3  p185307  525fdbb6ec7f538a48beebaa0a51b24f            Mr.           NC   \n",
       "4  p013780  a63b5547a7239eae4c1872670848e61a            Mr.           CA   \n",
       "\n",
       "  project_submitted_datetime project_grade_category  \\\n",
       "0        2016-11-18 14:45:59          Grades PreK-2   \n",
       "1        2017-04-26 15:57:28             Grades 3-5   \n",
       "2        2017-01-01 22:57:44             Grades 3-5   \n",
       "3        2016-08-12 15:42:11             Grades 3-5   \n",
       "4        2016-08-06 09:09:11             Grades 6-8   \n",
       "\n",
       "            project_subject_categories  \\\n",
       "0                  Literacy & Language   \n",
       "1    Music & The Arts, Health & Sports   \n",
       "2  Math & Science, Literacy & Language   \n",
       "3                      Health & Sports   \n",
       "4                      Health & Sports   \n",
       "\n",
       "            project_subject_subcategories  \\\n",
       "0                                Literacy   \n",
       "1            Performing Arts, Team Sports   \n",
       "2  Applied Sciences, Literature & Writing   \n",
       "3                       Health & Wellness   \n",
       "4                       Health & Wellness   \n",
       "\n",
       "                                       project_title  \\\n",
       "0                           Super Sight Word Centers   \n",
       "1                             Keep Calm and Dance On   \n",
       "2                              Lets 3Doodle to Learn   \n",
       "3  \\\"Kid Inspired\\\" Equipment to Increase Activit...   \n",
       "4   We need clean water for our culinary arts class!   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Our elementary school is a culturally rich sch...   \n",
       "2  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
       "3  My students are the greatest students but are ...   \n",
       "4  My students are athletes and students who are ...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  I currently have a differentiated sight word c...             NaN   \n",
       "1  We strive to provide our diverse population of...             NaN   \n",
       "2  We are looking to add some 3Doodler to our cla...             NaN   \n",
       "3  The student's project which is totally \\\"kid-i...             NaN   \n",
       "4  For some reason in our kitchen the water comes...             NaN   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
       "1             NaN  My students need matching shirts to wear for d...   \n",
       "2             NaN  My students need the 3doodler. We are an SEM s...   \n",
       "3             NaN  My students need balls and other activity equi...   \n",
       "4             NaN  My students need a water filtration system for...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \n",
       "0                                            26                    1  \n",
       "1                                             1                    0  \n",
       "2                                             5                    1  \n",
       "3                                            16                    0  \n",
       "4                                            42                    1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reference: https://colab.research.google.com/drive/1QhSnbh-WJVGZjQJF8u974msOL_vAgMeS#scrollTo=PlAGuj5kuZm9\n",
    "## https://github.com/eisenjulian/nlp_estimator_tutorial/blob/master/nlp_estimators.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard import summary as summary_lib\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "dir='/Users/xinwang/ai/dataset/kaggle/DonorsChoose/'\n",
    "train_file='train_1.csv'\n",
    "eval_file='train_2.csv'\n",
    "eval_file='train_2.csv'\n",
    "test_file='test.csv'\n",
    "resource_file='resources.csv'\n",
    "SEED=1000\n",
    "positive_sample_size=100 \n",
    "\n",
    "train_df = pd.read_csv(dir + train_file)\n",
    "eval_df = pd.read_csv(dir + eval_file)\n",
    "test_df = pd.read_csv(dir + test_file)\n",
    "resource_df = pd.read_csv(dir + resource_file)\n",
    "label = LabelEncoder()\n",
    "low_memory=False\n",
    "\n",
    "\n",
    "def sampleData():\n",
    "    train_label_1_df = train_df[train_df['project_is_approved']==1].sample(n=positive_sample_size,\n",
    "                                                                           random_state=SEED)\n",
    "    train_label_0_df = train_df[train_df['project_is_approved']==0]\n",
    "\n",
    "    train_data = pd.concat([train_label_1_df,train_label_0_df])\n",
    "    train_data = shuffle(train_data)\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "train_df.dropna(subset=[\"teacher_prefix\"], inplace=True)\n",
    "eval_df.dropna(subset=[\"teacher_prefix\"], inplace=True)\n",
    "\n",
    "train_data = train_df\n",
    "eval_data = eval_df\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpv5h92027/bow_sparse', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11ea2e0f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "text_2_vec data shape: (29997, 200)\n",
      "text_2_vec data shape: (29999, 200)\n",
      "x_train.shape (29997, 200)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpv5h92027/bow_sparse/model.ckpt.\n",
      "INFO:tensorflow:loss = 69.31472, step = 1\n",
      "INFO:tensorflow:global_step/sec: 68.3857\n",
      "INFO:tensorflow:loss = 67.44044, step = 101 (1.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.972\n",
      "INFO:tensorflow:loss = 44.321415, step = 201 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.743\n",
      "INFO:tensorflow:loss = 31.884056, step = 301 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.037\n",
      "INFO:tensorflow:loss = 46.318913, step = 401 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.981\n",
      "INFO:tensorflow:loss = 30.999775, step = 501 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.182\n",
      "INFO:tensorflow:loss = 31.329527, step = 601 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.925\n",
      "INFO:tensorflow:loss = 43.21962, step = 701 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.969\n",
      "INFO:tensorflow:loss = 36.00348, step = 801 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.782\n",
      "INFO:tensorflow:loss = 27.605356, step = 901 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.362\n",
      "INFO:tensorflow:loss = 46.374252, step = 1001 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.062\n",
      "INFO:tensorflow:loss = 28.601604, step = 1101 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.667\n",
      "INFO:tensorflow:loss = 29.572176, step = 1201 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.821\n",
      "INFO:tensorflow:loss = 28.046396, step = 1301 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.684\n",
      "INFO:tensorflow:loss = 29.845467, step = 1401 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.496\n",
      "INFO:tensorflow:loss = 27.599913, step = 1501 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.344\n",
      "INFO:tensorflow:loss = 29.145546, step = 1601 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.862\n",
      "INFO:tensorflow:loss = 19.356348, step = 1701 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.714\n",
      "INFO:tensorflow:loss = 27.933437, step = 1801 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.059\n",
      "INFO:tensorflow:loss = 29.602411, step = 1901 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.786\n",
      "INFO:tensorflow:loss = 16.048906, step = 2001 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.205\n",
      "INFO:tensorflow:loss = 29.606976, step = 2101 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.736\n",
      "INFO:tensorflow:loss = 32.25934, step = 2201 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.485\n",
      "INFO:tensorflow:loss = 21.427843, step = 2301 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.588\n",
      "INFO:tensorflow:loss = 24.180822, step = 2401 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.849\n",
      "INFO:tensorflow:loss = 28.863483, step = 2501 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.91\n",
      "INFO:tensorflow:loss = 20.952932, step = 2601 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.188\n",
      "INFO:tensorflow:loss = 27.927593, step = 2701 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.834\n",
      "INFO:tensorflow:loss = 30.760801, step = 2801 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.937\n",
      "INFO:tensorflow:loss = 25.416584, step = 2901 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.542\n",
      "INFO:tensorflow:loss = 26.251423, step = 3001 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.267\n",
      "INFO:tensorflow:loss = 32.72767, step = 3101 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.158\n",
      "INFO:tensorflow:loss = 19.804764, step = 3201 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.066\n",
      "INFO:tensorflow:loss = 24.333176, step = 3301 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.333\n",
      "INFO:tensorflow:loss = 24.562126, step = 3401 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.998\n",
      "INFO:tensorflow:loss = 15.318674, step = 3501 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.526\n",
      "INFO:tensorflow:loss = 32.197754, step = 3601 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.605\n",
      "INFO:tensorflow:loss = 27.260988, step = 3701 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.686\n",
      "INFO:tensorflow:loss = 13.029369, step = 3801 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.409\n",
      "INFO:tensorflow:loss = 25.28445, step = 3901 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.531\n",
      "INFO:tensorflow:loss = 29.329905, step = 4001 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.421\n",
      "INFO:tensorflow:loss = 18.778034, step = 4101 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.382\n",
      "INFO:tensorflow:loss = 25.585373, step = 4201 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.975\n",
      "INFO:tensorflow:loss = 18.336863, step = 4301 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.892\n",
      "INFO:tensorflow:loss = 22.810297, step = 4401 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.8\n",
      "INFO:tensorflow:loss = 20.472507, step = 4501 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.141\n",
      "INFO:tensorflow:loss = 17.822655, step = 4601 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.485\n",
      "INFO:tensorflow:loss = 17.500113, step = 4701 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.06\n",
      "INFO:tensorflow:loss = 23.188435, step = 4801 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.964\n",
      "INFO:tensorflow:loss = 16.236895, step = 4901 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.189\n",
      "INFO:tensorflow:loss = 19.371717, step = 5001 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.817\n",
      "INFO:tensorflow:loss = 22.730816, step = 5101 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.974\n",
      "INFO:tensorflow:loss = 28.515491, step = 5201 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.263\n",
      "INFO:tensorflow:loss = 20.301516, step = 5301 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.797\n",
      "INFO:tensorflow:loss = 24.306036, step = 5401 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.996\n",
      "INFO:tensorflow:loss = 18.720926, step = 5501 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.095\n",
      "INFO:tensorflow:loss = 16.41032, step = 5601 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.043\n",
      "INFO:tensorflow:loss = 24.176527, step = 5701 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.55\n",
      "INFO:tensorflow:loss = 17.150879, step = 5801 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.487\n",
      "INFO:tensorflow:loss = 18.197521, step = 5901 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.072\n",
      "INFO:tensorflow:loss = 20.93854, step = 6001 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.103\n",
      "INFO:tensorflow:loss = 24.386385, step = 6101 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.963\n",
      "INFO:tensorflow:loss = 14.931417, step = 6201 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.413\n",
      "INFO:tensorflow:loss = 19.716166, step = 6301 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.748\n",
      "INFO:tensorflow:loss = 19.189924, step = 6401 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.707\n",
      "INFO:tensorflow:loss = 14.420134, step = 6501 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.11\n",
      "INFO:tensorflow:loss = 22.107956, step = 6601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.676\n",
      "INFO:tensorflow:loss = 25.866789, step = 6701 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.343\n",
      "INFO:tensorflow:loss = 16.629906, step = 6801 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.423\n",
      "INFO:tensorflow:loss = 18.310276, step = 6901 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.926\n",
      "INFO:tensorflow:loss = 19.161493, step = 7001 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.886\n",
      "INFO:tensorflow:loss = 13.628277, step = 7101 (0.305 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 344.166\n",
      "INFO:tensorflow:loss = 25.023487, step = 7201 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.762\n",
      "INFO:tensorflow:loss = 27.745167, step = 7301 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.833\n",
      "INFO:tensorflow:loss = 18.377949, step = 7401 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.035\n",
      "INFO:tensorflow:loss = 21.372732, step = 7501 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.648\n",
      "INFO:tensorflow:loss = 24.568289, step = 7601 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.269\n",
      "INFO:tensorflow:loss = 14.234396, step = 7701 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.879\n",
      "INFO:tensorflow:loss = 17.925903, step = 7801 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.211\n",
      "INFO:tensorflow:loss = 16.12458, step = 7901 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.216\n",
      "INFO:tensorflow:loss = 19.334566, step = 8001 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.241\n",
      "INFO:tensorflow:loss = 17.856047, step = 8101 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.061\n",
      "INFO:tensorflow:loss = 20.048056, step = 8201 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.917\n",
      "INFO:tensorflow:loss = 14.195651, step = 8301 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.618\n",
      "INFO:tensorflow:loss = 25.307852, step = 8401 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.714\n",
      "INFO:tensorflow:loss = 23.514729, step = 8501 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.27\n",
      "INFO:tensorflow:loss = 14.074487, step = 8601 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.389\n",
      "INFO:tensorflow:loss = 25.088152, step = 8701 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.754\n",
      "INFO:tensorflow:loss = 15.548428, step = 8801 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.738\n",
      "INFO:tensorflow:loss = 13.702017, step = 8901 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.77\n",
      "INFO:tensorflow:loss = 23.280537, step = 9001 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.067\n",
      "INFO:tensorflow:loss = 20.063747, step = 9101 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.976\n",
      "INFO:tensorflow:loss = 14.379388, step = 9201 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.025\n",
      "INFO:tensorflow:loss = 21.991587, step = 9301 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.264\n",
      "INFO:tensorflow:loss = 18.195887, step = 9401 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.78\n",
      "INFO:tensorflow:loss = 14.548205, step = 9501 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.809\n",
      "INFO:tensorflow:loss = 20.29285, step = 9601 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.304\n",
      "INFO:tensorflow:loss = 19.481241, step = 9701 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.569\n",
      "INFO:tensorflow:loss = 16.691162, step = 9801 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.702\n",
      "INFO:tensorflow:loss = 24.355295, step = 9901 (0.291 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpv5h92027/bow_sparse/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 21.712954.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-31-13:36:30\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpv5h92027/bow_sparse/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-31-13:36:33\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.7893263, accuracy_baseline = 0.84859496, auc = 0.50487417, auc_precision_recall = 0.86234486, average_loss = 0.71029466, global_step = 10000, label/mean = 0.84859496, loss = 71.0271, precision = 0.84994334, prediction/mean = 0.84766006, recall = 0.91291195\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpv5h92027/bow_sparse/model.ckpt-10000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hz/zfwx8n_d19g70bf5p8jpl4f43zxvln/T/tmpv5h92027/bow_sparse/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "vocab_size=30000\n",
    "embedding_size=50\n",
    "sentence_size=200\n",
    "\n",
    "project_essay_1 = tf.feature_column.categorical_column_with_identity('x', vocab_size)\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns=[project_essay_1], \n",
    "                                           model_dir=os.path.join(model_dir, 'bow_sparse'))\n",
    "\n",
    "target = 'project_is_approved'\n",
    "model_dir = tempfile.mkdtemp()\n",
    "\n",
    "pad_id = 0\n",
    "start_id = 1\n",
    "oov_id = 2\n",
    "index_offset = 2\n",
    "\n",
    "def process_text(feature_name, data_set):\n",
    "    vocabulary_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(sentence_size)\n",
    "    data = vocabulary_processor.fit_transform(data_set[feature_name].values)\n",
    "    \n",
    "    array = np.array(list(data))\n",
    "    print('vocabulary size ', len(vocabulary_processor.vocabulary_))\n",
    "    \n",
    "    return array\n",
    "\n",
    "\n",
    "def text_2_vec(feature_name, data_set):\n",
    "    texts = data_set[feature_name].values\n",
    "    \n",
    "    tokenizer = Tokenizer(vocab_size)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequence_data = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    data = sequence.pad_sequences(sequence_data, \n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)\n",
    "    print(\"text_2_vec data shape:\", data.shape)\n",
    "    \n",
    "    return data\n",
    "\n",
    "project_essay_1_train = text_2_vec('project_essay_1', train_data)\n",
    "project_essay_1_eval = text_2_vec('project_essay_1', eval_data)\n",
    "\n",
    "def parser(x, y):\n",
    "    features = {\"x\": x }\n",
    "    return features, y\n",
    "\n",
    "def train_input_fn():\n",
    "    x_train = project_essay_1_train\n",
    "    y_train = train_data[target]\n",
    "    \n",
    "    print('x_train.shape',x_train.shape)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    dataset = dataset.shuffle(buffer_size=100)\n",
    "    dataset = dataset.batch(100)\n",
    "    \n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    return iterator.get_next()\n",
    "    \n",
    "def eval_input_fn():\n",
    "    x_test = project_essay_1_eval\n",
    "    y_test = eval_data[target]\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    dataset = dataset.batch(100)\n",
    "    \n",
    "    dataset = dataset.map(parser)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "\n",
    "all_classifiers = {}\n",
    "def train_and_evaluate(classifier):\n",
    "    all_classifiers[classifier.model_dir] = classifier\n",
    "    classifier.train(input_fn=train_input_fn, steps = 10000)\n",
    "    eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "    \n",
    "    predictions = np.array([p['logistic'][0] for p in classifier.predict(\n",
    "        input_fn=eval_input_fn)])\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    pr = summary_lib.pr_curve('precision_recall', predictions=predictions, \n",
    "                              labels = eval_data[target].astype(bool),\n",
    "                              num_thresholds = 21)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(os.path.join(classifier.model_dir, 'eval'),\n",
    "                                      sess.graph)\n",
    "        writer.add_summary(sess.run(pr), global_step = 0)\n",
    "        writer.close()\n",
    "\n",
    "\n",
    "train_and_evaluate(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
