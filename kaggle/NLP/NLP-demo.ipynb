{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xinwang/.keras/datasets/train.tfrecord\n",
      "/Users/xinwang/.keras/datasets/test.tfrecord\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import io\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "train_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
    "test_url='https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
    "\n",
    "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
    "print(train_path)\n",
    "\n",
    "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'terms': array([b'but', b'it', b'does', b'have', b'some', b'good', b'action',\n",
      "       b'and', b'a', b'plot', b'that', b'is', b'somewhat', b'interesting',\n",
      "       b'.', b'nevsky', b'acts', b'like', b'a', b'body', b'builder',\n",
      "       b'and', b'he', b'isn', b\"'\", b't', b'all', b'that', b'attractive',\n",
      "       b',', b'in', b'fact', b',', b'imo', b',', b'he', b'is', b'ugly',\n",
      "       b'.', b'(', b'his', b'acting', b'skills', b'lack', b'everything',\n",
      "       b'!', b')', b'sascha', b'is', b'played', b'very', b'well', b'by',\n",
      "       b'joanna', b'pacula', b',', b'but', b'she', b'needed', b'more',\n",
      "       b'lines', b'than', b'she', b'was', b'given', b',', b'her',\n",
      "       b'character', b'needed', b'to', b'be', b'developed', b'.',\n",
      "       b'there', b'are', b'way', b'too', b'many', b'men', b'in', b'this',\n",
      "       b'story', b',', b'there', b'is', b'zero', b'romance', b',', b'too',\n",
      "       b'much', b'action', b',', b'and', b'way', b'too', b'dumb', b'of',\n",
      "       b'an', b'ending', b'.', b'it', b'is', b'very', b'violent', b'.',\n",
      "       b'i', b'did', b'however', b'love', b'the', b'scenery', b',',\n",
      "       b'this', b'movie', b'takes', b'you', b'all', b'over', b'the',\n",
      "       b'world', b',', b'and', b'that', b'is', b'a', b'bonus', b'.', b'i',\n",
      "       b'also', b'liked', b'how', b'it', b'had', b'some', b'stuff',\n",
      "       b'about', b'the', b'mafia', b'in', b'it', b',', b'not', b'too',\n",
      "       b'much', b'or', b'too', b'little', b',', b'but', b'enough',\n",
      "       b'that', b'it', b'got', b'my', b'attention', b'.', b'the',\n",
      "       b'actors', b'needed', b'to', b'be', b'more', b'handsome', b'.',\n",
      "       b'.', b'.', b'the', b'biggest', b'problem', b'i', b'had', b'was',\n",
      "       b'that', b'nevsky', b'was', b'just', b'too', b'normal', b',',\n",
      "       b'not', b'sexy', b'enough', b'.', b'i', b'think', b'for', b'most',\n",
      "       b'guys', b',', b'sascha', b'will', b'be', b'hot', b'enough', b',',\n",
      "       b'but', b'for', b'us', b'ladies', b'that', b'are', b'fans', b'of',\n",
      "       b'action', b',', b'nevsky', b'just', b'doesn', b\"'\", b't', b'cut',\n",
      "       b'it', b'.', b'overall', b',', b'this', b'movie', b'was', b'fine',\n",
      "       b',', b'i', b'didn', b\"'\", b't', b'love', b'it', b'nor', b'did',\n",
      "       b'i', b'hate', b'it', b',', b'just', b'found', b'it', b'to', b'be',\n",
      "       b'another', b'normal', b'action', b'flick', b'.'], dtype=object)}, array([0.], dtype=float32))\n",
      "({'terms': array([b'i', b'have', b'given', b'this', b'film', b'an', b'elevated',\n",
      "       b'rating', b'of', b'2', b'stars', b'as', b'i', b'personally',\n",
      "       b'appear', b'in', b'minutes', b'##', b'and', b'##', b'of', b'the',\n",
      "       b'film', b'.', b'.', b'.', b'.', b'the', b'road', b'side', b'bar',\n",
      "       b'scene', b'in', b'russia', b'.', b'in', b'this', b'scene', b'the',\n",
      "       b'director', b'of', b'the', b'movie', b'offered', b'me', b'the',\n",
      "       b'immortal', b'line', b'-', b'\"', b'##', b'dollars', b'.', b'.',\n",
      "       b'you', b'drink', b'and', b'talk', b'\"', b',', b'but', b'i',\n",
      "       b'felt', b'that', b'my', b'polish', b'counterpart', b'could',\n",
      "       b'speak', b'in', b'a', b'more', b'convincing', b'russian',\n",
      "       b'accent', b'than', b'i', b'could', b',', b'so', b'i', b'declined',\n",
      "       b'to', b'take', b'this', b'speaking', b'part', b'on', b'.', b'i',\n",
      "       b'was', b'slightly', b'starstruck', b'as', b'this', b'was', b'my',\n",
      "       b'first', b'film', b'experience', b'.', b'.', b'.', b'.', b'and',\n",
      "       b'who', b'knows', b'.', b'.', b'.', b'these', b'lines', b'could',\n",
      "       b'have', b'ended', b'up', b'there', b'with', b'lines', b'such',\n",
      "       b'as', b'\"', b'i', b\"'\", b'll', b'be', b'back', b'\"', b'and', b'\"',\n",
      "       b'quite', b'frankly', b'my', b'dear', b',', b'i', b'don', b\"'\",\n",
      "       b't', b'give', b'a', b'damn', b'\"', b'.', b'had', b'i', b'spoken',\n",
      "       b'that', b'one', b'line', b'then', b'my', b'name', b'would',\n",
      "       b'appear', b'in', b'the', b'credits', b'of', b'rancid',\n",
      "       b'aluminium', b'as', b\"'\", b'heavy', b'1', b\"'\", b'instead', b'of',\n",
      "       b'the', b'name', b'of', b'ryszard', b'janikowski', b'.', b'as',\n",
      "       b'time', b'goes', b'on', b',', b'i', b'am', b'counting', b'myself',\n",
      "       b'lucky', b'that', b'my', b'name', b'is', b'in', b'no', b'way',\n",
      "       b'connected', b'to', b'this', b'film', b'.', b'even', b'though',\n",
      "       b'i', b'spent', b'a', b'whole', b'day', b'on', b'the', b'set',\n",
      "       b',', b'in', b'south', b'wales', b'hotspot', b'barry', b'island',\n",
      "       b',', b'no', b'one', b'could', b'tell', b'me', b'what', b'the',\n",
      "       b'actual', b'storyline', b'was', b'.', b'the', b'caterers', b'and',\n",
      "       b'the', b'wardrobe', b'lady', b'all', b'concurred', b'that', b'it',\n",
      "       b'appeared', b'to', b'have', b'a', b'lot', b'of', b'swearing',\n",
      "       b'and', b'nudity', b'in', b'it', b'.', b'.', b'.', b'.', b'.',\n",
      "       b'things', b'could', b'certainly', b'have', b'been', b'worse',\n",
      "       b'if', b'i', b\"'\", b'd', b'ended', b'up', b'naked', b'in', b'this',\n",
      "       b'most', b'dreadful', b'of', b'films', b'.', b'.', b'.', b'.',\n",
      "       b'still', b'.', b'.', b'.', b'.', b'.', b'on', b'the', b'positive',\n",
      "       b'side', b'.', b'.', b'.', b'.', b'i', b'got', b'chatting', b'to',\n",
      "       b'rhys', b'ifans', b'during', b'one', b'break', b'.', b'i', b'had',\n",
      "       b'no', b'idea', b'who', b'he', b'was', b',', b'as', b'\"',\n",
      "       b'notting', b'hill', b'\"', b'was', b'yet', b'to', b'be',\n",
      "       b'released', b',', b'and', b'not', b'an', b'inkling', b'that',\n",
      "       b'he', b'might', b'be', b'welsh', b'.', b'made', b'various',\n",
      "       b'inappropriate', b'comments', b'about', b'what', b'an', b'awful',\n",
      "       b'pit', b'barry', b'island', b'had', b'become', b'since', b'my',\n",
      "       b'childhood', b'visits', b'there', b'in', b'the', b'##s', b'and',\n",
      "       b'##s', b'.', b'it', b'was', b'only', b'when', b'keith', b'allen',\n",
      "       b'showed', b'up', b'that', b'i', b'realised', b'i', b'was', b'in',\n",
      "       b'a', b'quality', b'production', b'.', b'.', b'.', b'.', b'.',\n",
      "       b'.', b'.', b'.'], dtype=object)}, array([0.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "def _parse_function(record):\n",
    "    features = {\n",
    "        \"terms\":tf.VarLenFeature(dtype=tf.string),\n",
    "        \"labels\":tf.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "    }\n",
    "    \n",
    "    parsed_features = tf.parse_single_example(record, features)\n",
    "    \n",
    "    terms = parsed_features['terms'].values\n",
    "    labels = parsed_features['labels']\n",
    "    \n",
    "    return {'terms':terms}, labels\n",
    "\n",
    "\n",
    "ds = tf.data.TFRecordDataset(train_path)\n",
    "\n",
    "ds = ds.map(_parse_function)\n",
    "\n",
    "n = ds.make_one_shot_iterator().get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(2):\n",
    "        print(sess.run(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set metrics:\n",
      "accuracy 0.78592\n",
      "accuracy_baseline 0.5\n",
      "auc 0.8710361\n",
      "auc_precision_recall 0.8641522\n",
      "average_loss 0.45636493\n",
      "label/mean 0.5\n",
      "loss 11.409123\n",
      "precision 0.7946414\n",
      "prediction/mean 0.4681327\n",
      "recall 0.77112\n",
      "global_step 1000\n",
      "-------\n",
      "Test set metrics:\n",
      "accuracy 0.7798\n",
      "accuracy_baseline 0.5\n",
      "auc 0.8682654\n",
      "auc_precision_recall 0.8616555\n",
      "average_loss 0.45892027\n",
      "label/mean 0.5\n",
      "loss 11.473007\n",
      "precision 0.7889779\n",
      "prediction/mean 0.46761262\n",
      "recall 0.76392\n",
      "global_step 1000\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "def _input_fn(input_filenames, n_epochs = None, shuffle=True):\n",
    "    ds = tf.data.TFRecordDataset(input_filenames)\n",
    "    ds = ds.map(_parse_function)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(10000)\n",
    "    \n",
    "    ds = ds.padded_batch(25, ds.output_shapes)\n",
    "    \n",
    "    ds = ds.repeat(n_epochs)\n",
    "    \n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "\n",
    "informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n",
    "                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n",
    "                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n",
    "                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n",
    "                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n",
    "                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n",
    "                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n",
    "                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n",
    "                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n",
    "                     \"drama\", \"family\")\n",
    "\n",
    "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key='terms',\n",
    "                                                                                vocabulary_list=informative_terms)\n",
    "\n",
    "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "feature_columns = [terms_feature_column]\n",
    "\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns = feature_columns,\n",
    "                                          optimizer = my_optimizer)\n",
    "classifier.train(input_fn=lambda: _input_fn([train_path]),\n",
    "                steps=1000)\n",
    "\n",
    "evaluation_metrics = classifier.evaluate(input_fn=lambda: _input_fn([train_path]),\n",
    "                                        steps=1000)\n",
    "\n",
    "print('Training set metrics:')\n",
    "for m in evaluation_metrics:\n",
    "    print(m, evaluation_metrics[m])\n",
    "print('-------')\n",
    "\n",
    "\n",
    "evaluation_metrics = classifier.evaluate(input_fn=lambda: _input_fn([test_path]),\n",
    "                                        steps=1000)\n",
    "\n",
    "print('Test set metrics:')\n",
    "for m in evaluation_metrics:\n",
    "    print(m, evaluation_metrics[m])\n",
    "print('--------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
